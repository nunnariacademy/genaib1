{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 OpenAI API Deep Dive — Authentication, Request Structure & Streaming\n",
    "\n",
    "## Playground Notebook\n",
    "\n",
    "In this notebook, we'll work directly with the **OpenAI Python SDK** to understand:\n",
    "\n",
    "| Topic | What You'll Learn |\n",
    "|-------|-------------------|\n",
    "| **API Authentication** | How API keys work, secure storage with `.env`, and client setup |\n",
    "| **Request Structure** | The anatomy of `chat.completions.create()` — roles, parameters, response object |\n",
    "| **Streaming** | Real-time token-by-token responses vs. standard blocking calls |\n",
    "\n",
    "> **Model:** `gpt-4o-mini` — cost-efficient and capable for all experiments below.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client ready | Model: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import display, Markdown, HTML\n",
    "\n",
    "# ============================================================\n",
    "#  CONFIGURATION\n",
    "# ============================================================\n",
    "load_dotenv()  # loads OPENAI_API_KEY from .env file\n",
    "\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "\n",
    "client = OpenAI()  # automatically reads OPENAI_API_KEY from env\n",
    "\n",
    "print(f\"\\u2705 Client ready | Model: {MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Helpers loaded\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "#  HELPER FUNCTIONS\n",
    "# ============================================================\n",
    "\n",
    "def chat(messages, max_tokens=150, **kwargs):\n",
    "    \"\"\"Send messages to OpenAI and display the response.\"\"\"\n",
    "    start = time.time()\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        max_tokens=max_tokens,\n",
    "        **kwargs\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    content = response.choices[0].message.content\n",
    "    display(Markdown(content))\n",
    "    print(f\"\\n\\u23f1\\ufe0f {elapsed:.2f}s | Tokens: {response.usage.prompt_tokens}+{response.usage.completion_tokens}={response.usage.total_tokens}\")\n",
    "    return response\n",
    "\n",
    "\n",
    "def show_messages(messages):\n",
    "    \"\"\"Pretty-print the message list being sent.\"\"\"\n",
    "    colors = {\"system\": \"#e74c3c\", \"user\": \"#3498db\", \"assistant\": \"#2ecc71\"}\n",
    "    html = \"\"\n",
    "    for msg in messages:\n",
    "        role = msg[\"role\"]\n",
    "        color = colors.get(role, \"#888\")\n",
    "        html += (\n",
    "            f'<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid {color};'\n",
    "            f'background:#1e1e1e;border-radius:4px;\">'\n",
    "            f'<strong style=\"color:{color};text-transform:uppercase;\">{role}</strong>'\n",
    "            f'<br><span style=\"color:#ccc;\">{msg[\"content\"]}</span></div>'\n",
    "        )\n",
    "    display(HTML(html))\n",
    "\n",
    "\n",
    "print(\"\\u2705 Helpers loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. API Authentication — Setting Up Securely\n",
    "\n",
    "Your API key is a **secret token** that identifies and authorizes your application.\n",
    "\n",
    "```\n",
    "\\u2717  NEVER do this:\n",
    "    client = OpenAI(api_key=\"sk-abc123...\")   # hardcoded = leaked\n",
    "\n",
    "\\u2713  ALWAYS do this:\n",
    "    # .env file:  OPENAI_API_KEY=sk-abc123...\n",
    "    load_dotenv()\n",
    "    client = OpenAI()  # reads from environment automatically\n",
    "```\n",
    "\n",
    "### Experiment 1A: Verify Your Key is Loaded (Without Exposing It)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ API Key loaded: sk-proj...ctAA\n",
      "   Key length: 164 characters\n"
     ]
    }
   ],
   "source": [
    "# Never print your full key! Only show enough to confirm it's loaded.\n",
    "key = os.environ.get(\"OPENAI_API_KEY\", \"NOT SET\")\n",
    "\n",
    "if key == \"NOT SET\":\n",
    "    print(\"\\u274c OPENAI_API_KEY not found in environment!\")\n",
    "    print(\"   Create a .env file with: OPENAI_API_KEY=sk-...\")\n",
    "else:\n",
    "    masked = key[:7] + \"...\" + key[-4:]\n",
    "    print(f\"\\u2705 API Key loaded: {masked}\")\n",
    "    print(f\"   Key length: {len(key)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1B: What Happens with a Bad Key?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ AuthenticationError caught!\n",
      "   Status: 401\n",
      "   Message: Incorrect API key provided: sk-fake-*****2345. You can find your API key at https://platform.openai.com/account/api-keys....\n",
      "\n",
      "✅ This is exactly what you'd see with an invalid or expired key.\n"
     ]
    }
   ],
   "source": [
    "from openai import AuthenticationError\n",
    "\n",
    "bad_client = OpenAI(api_key=\"sk-fake-key-12345\")\n",
    "\n",
    "try:\n",
    "    bad_client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": \"Hi\"}],\n",
    "        max_tokens=5\n",
    "    )\n",
    "except AuthenticationError as e:\n",
    "    print(f\"\\u274c AuthenticationError caught!\")\n",
    "    print(f\"   Status: {e.status_code}\")\n",
    "    print(f\"   Message: {e.body['message']}...\")\n",
    "    print(f\"\\n\\u2705 This is exactly what you'd see with an invalid or expired key.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Request Structure — Anatomy of an API Call\n",
    "\n",
    "Every request goes through `client.chat.completions.create()`. The two **required** parameters are:\n",
    "\n",
    "| Parameter | Required? | Description |\n",
    "|-----------|-----------|-------------|\n",
    "| `model` | \\u2705 Yes | Which model to use (e.g. `gpt-4o-mini`) |\n",
    "| `messages` | \\u2705 Yes | List of role/content dicts — the conversation |\n",
    "| `max_tokens` | Optional | Max tokens in the response |\n",
    "| `temperature` | Optional | Randomness (0.0–2.0) |\n",
    "| `top_p` | Optional | Nucleus sampling threshold |\n",
    "| `stop` | Optional | Sequences that halt generation |\n",
    "| `n` | Optional | Number of completions to generate |\n",
    "\n",
    "### The 3 Message Roles\n",
    "\n",
    "```\n",
    "system    \\u2192  Sets behavior, persona, constraints (processed first)\n",
    "user      \\u2192  The human's input — questions, data, instructions\n",
    "assistant \\u2192  Model's prior responses (for multi-turn context)\n",
    "```\n",
    "\n",
    "### Experiment 2A: Minimal Request — Just model + messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">What is an API? One sentence.</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "An API, or Application Programming Interface, is a set of rules and protocols that allows different software applications to communicate and interact with each other."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ 2.03s | Tokens: 15+28=43\n"
     ]
    }
   ],
   "source": [
    "# The simplest possible API call\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is an API? One sentence.\"}\n",
    "]\n",
    "\n",
    "show_messages(messages)\n",
    "response = chat(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2B: Full Request with System Prompt + Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #e74c3c;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#e74c3c;text-transform:uppercase;\">system</strong><br><span style=\"color:#ccc;\">You are a concise technical writer. Max 2 sentences.</span></div><div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">Explain REST APIs.</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "REST APIs (Representational State Transfer Application Programming Interfaces) are architectural styles that allow different software applications to communicate over the internet using standard HTTP methods like GET, POST, PUT, and DELETE. They enable stateless interactions and resource manipulation through URLs, making it easier to integrate and scale web services."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ 2.24s | Tokens: 27+59=86\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a concise technical writer. Max 2 sentences.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Explain REST APIs.\"}\n",
    "]\n",
    "\n",
    "show_messages(messages)\n",
    "response = chat(messages, temperature=0.3, max_tokens=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2C: Inspecting the Full Response Object\n",
    "\n",
    "The API returns a rich response object. Let's explore every field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─ RESPONSE OBJECT ──────────────────────────────────┐\n",
      "│ id:              chatcmpl-DED48M7lld5MdvpMP7tTMFmKIjs5A\n",
      "│ model:           gpt-4o-mini-2024-07-18\n",
      "│ created:         1772279188\n",
      "│ object:          chat.completion\n",
      "│\n",
      "│ ┌─ choices[0] ──────────────────────────┐\n",
      "│ │ index:          0\n",
      "│ │ finish_reason:  stop\n",
      "│ │ role:           assistant\n",
      "│ │ content:        Hello! How can I assist you today?\n",
      "│ └──────────────────────────────────────┘\n",
      "│\n",
      "│ ┌─ usage ───────────────────────────────┐\n",
      "│ │ prompt_tokens:     10\n",
      "│ │ completion_tokens: 9\n",
      "│ │ total_tokens:      19\n",
      "│ └──────────────────────────────────────┘\n",
      "└──────────────────────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Say hello.\"}],\n",
    "    max_tokens=20\n",
    ")\n",
    "\n",
    "print(\"\\u250c\\u2500 RESPONSE OBJECT \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510\")\n",
    "print(f\"\\u2502 id:              {response.id}\")\n",
    "print(f\"\\u2502 model:           {response.model}\")\n",
    "print(f\"\\u2502 created:         {response.created}\")\n",
    "print(f\"\\u2502 object:          {response.object}\")\n",
    "print(f\"\\u2502\")\n",
    "print(f\"\\u2502 \\u250c\\u2500 choices[0] \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510\")\n",
    "choice = response.choices[0]\n",
    "print(f\"\\u2502 \\u2502 index:          {choice.index}\")\n",
    "print(f\"\\u2502 \\u2502 finish_reason:  {choice.finish_reason}\")\n",
    "print(f\"\\u2502 \\u2502 role:           {choice.message.role}\")\n",
    "print(f\"\\u2502 \\u2502 content:        {choice.message.content}\")\n",
    "print(f\"\\u2502 \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518\")\n",
    "print(f\"\\u2502\")\n",
    "print(f\"\\u2502 \\u250c\\u2500 usage \\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2510\")\n",
    "print(f\"\\u2502 \\u2502 prompt_tokens:     {response.usage.prompt_tokens}\")\n",
    "print(f\"\\u2502 \\u2502 completion_tokens: {response.usage.completion_tokens}\")\n",
    "print(f\"\\u2502 \\u2502 total_tokens:      {response.usage.total_tokens}\")\n",
    "print(f\"\\u2502 \\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518\")\n",
    "print(f\"\\u2514\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2500\\u2518\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2D: `finish_reason` Values\n",
    "\n",
    "| Value | Meaning |\n",
    "|-------|---------|\n",
    "| `stop` | Model finished naturally |\n",
    "| `length` | Hit `max_tokens` limit — output was cut off |\n",
    "| `tool_calls` | Model wants to call a function (covered in 3.2) |\n",
    "| `content_filter` | Content was flagged and blocked |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "max_tokens=10 — Will it get cut off?\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">Write a poem about the ocean.</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "In the embrace of the ocean's hymn,  \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ 2.44s | Tokens: 14+10=24\n",
      "finish_reason: length\n",
      "\n",
      "⚠️ 'length' means the response was CUT OFF — it didn't finish naturally!\n",
      "\n",
      "============================================================\n",
      "max_tokens=60 — Enough room to finish\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">Write a 2-line poem about the ocean.</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Endless waves whisper secrets of the deep,  \n",
       "Where sunlit dreams and shadows softly sleep."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ 1.57s | Tokens: 17+19=36\n",
      "finish_reason: stop\n",
      "\n",
      "✅ 'stop' means the model finished on its own.\n"
     ]
    }
   ],
   "source": [
    "# Force a 'length' finish by setting max_tokens very low\n",
    "print(\"=\" * 60)\n",
    "print(\"max_tokens=10 — Will it get cut off?\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"Write a poem about the ocean.\"}]\n",
    "show_messages(messages)\n",
    "response = chat(messages, max_tokens=10)\n",
    "print(f\"finish_reason: {response.choices[0].finish_reason}\")\n",
    "print(f\"\\n\\u26a0\\ufe0f 'length' means the response was CUT OFF — it didn't finish naturally!\")\n",
    "\n",
    "# Now let it finish\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"max_tokens=60 — Enough room to finish\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "messages2 = [{\"role\": \"user\", \"content\": \"Write a 2-line poem about the ocean.\"}]\n",
    "show_messages(messages2)\n",
    "response2 = chat(messages2, max_tokens=60)\n",
    "print(f\"finish_reason: {response2.choices[0].finish_reason}\")\n",
    "print(f\"\\n\\u2705 'stop' means the model finished on its own.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2E: Multi-Turn Conversations\n",
    "\n",
    "OpenAI has **no built-in memory**. To continue a conversation, you must pass the **full history** with every request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MULTI-TURN: The model sees the full conversation history\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #e74c3c;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#e74c3c;text-transform:uppercase;\">system</strong><br><span style=\"color:#ccc;\">You are a helpful math tutor. Be concise.</span></div><div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">What is 15% of 200?</span></div><div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #2ecc71;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#2ecc71;text-transform:uppercase;\">assistant</strong><br><span style=\"color:#ccc;\">15% of 200 = 0.15 × 200 = 30.</span></div><div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">What was the previously generated answer?</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The previously generated answer is 30."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ 1.24s | Tokens: 62+8=70\n"
     ]
    }
   ],
   "source": [
    "conversation = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful math tutor. Be concise.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 15% of 200?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"15% of 200 = 0.15 \\u00d7 200 = 30.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What was the previously generated answer?\"}\n",
    "]\n",
    "\n",
    "print(\"MULTI-TURN: The model sees the full conversation history\")\n",
    "print(\"=\" * 60)\n",
    "show_messages(conversation)\n",
    "_ = chat(conversation, max_tokens=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TURN 1\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #e74c3c;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#e74c3c;text-transform:uppercase;\">system</strong><br><span style=\"color:#ccc;\">You are a travel guide. Give 1-sentence answers only.</span></div><div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">I'm visiting Tokyo. What's one must-see?</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "You must visit the historic Senso-ji Temple in Asakusa."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ 0.83s | Tokens: 34+15=49\n",
      "\n",
      "============================================================\n",
      "TURN 2\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #e74c3c;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#e74c3c;text-transform:uppercase;\">system</strong><br><span style=\"color:#ccc;\">You are a travel guide. Give 1-sentence answers only.</span></div><div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">I'm visiting Tokyo. What's one must-see?</span></div><div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #2ecc71;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#2ecc71;text-transform:uppercase;\">assistant</strong><br><span style=\"color:#ccc;\">You must visit the historic Senso-ji Temple in Asakusa.</span></div><div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">What food should I try there?</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "You should try authentic sushi at Tsukiji Outer Market."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ 0.64s | Tokens: 64+12=76\n",
      "\n",
      "============================================================\n",
      "TURN 3\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #e74c3c;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#e74c3c;text-transform:uppercase;\">system</strong><br><span style=\"color:#ccc;\">You are a travel guide. Give 1-sentence answers only.</span></div><div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">I'm visiting Tokyo. What's one must-see?</span></div><div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #2ecc71;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#2ecc71;text-transform:uppercase;\">assistant</strong><br><span style=\"color:#ccc;\">You must visit the historic Senso-ji Temple in Asakusa.</span></div><div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">What food should I try there?</span></div><div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #2ecc71;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#2ecc71;text-transform:uppercase;\">assistant</strong><br><span style=\"color:#ccc;\">You should try authentic sushi at Tsukiji Outer Market.</span></div><div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">Any etiquette tips?</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Always bow slightly when greeting or thanking someone, as it's a sign of respect."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ 2.13s | Tokens: 88+16=104\n",
      "\n",
      "============================================================\n",
      "ℹ️ Total messages in history: 7\n",
      "⚠️ Notice: token count GROWS each turn because we resend the entire history!\n"
     ]
    }
   ],
   "source": [
    "# Build a conversation dynamically — each response feeds into the next\n",
    "conversation = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a travel guide. Give 1-sentence answers only.\"}\n",
    "]\n",
    "\n",
    "user_turns = [\n",
    "    \"I'm visiting Tokyo. What's one must-see?\",\n",
    "    \"What food should I try there?\",\n",
    "    \"Any etiquette tips?\"\n",
    "]\n",
    "\n",
    "for i, user_msg in enumerate(user_turns, 1):\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"TURN {i}\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "\n",
    "    conversation.append({\"role\": \"user\", \"content\": user_msg})\n",
    "    show_messages(conversation)\n",
    "    response = chat(conversation, max_tokens=60)\n",
    "\n",
    "    assistant_msg = response.choices[0].message.content\n",
    "    conversation.append({\"role\": \"assistant\", \"content\": assistant_msg})\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"\\u2139\\ufe0f Total messages in history: {len(conversation)}\")\n",
    "print(\"\\u26a0\\ufe0f Notice: token count GROWS each turn because we resend the entire history!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Streaming Responses — Token by Token\n",
    "\n",
    "By default, the API generates the **complete response first**, then sends it all at once.\n",
    "\n",
    "With **streaming**, tokens arrive as they're generated — just like ChatGPT's typing effect.\n",
    "\n",
    "```\n",
    "Normal:    [wait 2s...] \\u2192 \\\"Here is the full response all at once.\\\"\n",
    "Streaming: H-e-r-e- -i-s- ... (tokens arrive one by one)\n",
    "```\n",
    "\n",
    "### Experiment 3A: Normal vs. Streaming — Side by Side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "NORMAL MODE (blocking — waits for full response)\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">List 3 benefits of exercise. One sentence each.</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "1. Exercise improves cardiovascular health by strengthening the heart and enhancing circulation, which lowers the risk of heart disease.  \n",
       "2. Regular physical activity boosts mental health by reducing symptoms of anxiety and depression while improving mood and cognitive function.  \n",
       "3. Engaging in consistent exercise aids in weight management by increasing metabolism and promoting fat loss while building lean muscle mass.  "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ 2.02s | Tokens: 18+71=89\n",
      "ℹ️ Entire response arrived at once after the wait.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "prompt = \"List 3 benefits of exercise. One sentence each.\"\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "# --- Normal (blocking) ---\n",
    "print(\"=\" * 60)\n",
    "print(\"NORMAL MODE (blocking — waits for full response)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "show_messages(messages)\n",
    "response = chat(messages, max_tokens=100)\n",
    "print(f\"\\u2139\\ufe0f Entire response arrived at once after the wait.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STREAMING MODE (tokens arrive as generated)\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">List 3 benefits of exercise. One sentence each.</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Exercise improves cardiovascular health by strengthening the heart and enhancing blood circulation, reducing the risk of heart disease.  \n",
      "2. Regular physical activity boosts mental health by releasing endorphins, which can alleviate symptoms of anxiety and depression.  \n",
      "3. Exercise helps maintain a healthy weight by burning calories and increasing metabolism, promoting overall physical fitness.  \n",
      "\n",
      "⏱️ Time to first token: 0.55s\n",
      "⏱️ Total time: 1.87s\n",
      "✅ Collected 402 characters while streaming\n"
     ]
    }
   ],
   "source": [
    "# --- Streaming ---\n",
    "print(\"=\" * 60)\n",
    "print(\"STREAMING MODE (tokens arrive as generated)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "show_messages(messages)\n",
    "\n",
    "start = time.time()\n",
    "first_token_time = None\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages,\n",
    "    max_tokens=100,\n",
    "    stream=True  # <-- just add this!\n",
    ")\n",
    "\n",
    "collected = \"\"\n",
    "for chunk in stream:\n",
    "    delta = chunk.choices[0].delta.content\n",
    "    if delta:\n",
    "        if first_token_time is None:\n",
    "            first_token_time = time.time() - start\n",
    "        print(delta, end=\"\", flush=True)\n",
    "        collected += delta\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"\\n\\n\\u23f1\\ufe0f Time to first token: {first_token_time:.2f}s\")\n",
    "print(f\"\\u23f1\\ufe0f Total time: {elapsed:.2f}s\")\n",
    "print(f\"\\u2705 Collected {len(collected)} characters while streaming\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3B: Inspecting Streaming Chunks\n",
    "\n",
    "Each chunk is a lightweight object — much simpler than the full response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">Say 'Hello World'</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk#   finish_reason    delta.content\n",
      "--------------------------------------------------\n",
      "0        -                ''\n",
      "1        -                'Hello'\n",
      "2        -                ' World'\n",
      "3        -                '!'\n",
      "4        stop             ''\n",
      "\n",
      "ℹ️ The last chunk has finish_reason='stop' and empty content.\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"Say 'Hello World'\"}]\n",
    "show_messages(messages)\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages,\n",
    "    max_tokens=10,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "print(f\"{'Chunk#':<8} {'finish_reason':<16} {'delta.content'}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for i, chunk in enumerate(stream):\n",
    "    choice = chunk.choices[0]\n",
    "    content = choice.delta.content or \"\"\n",
    "    reason = choice.finish_reason or \"-\"\n",
    "    print(f\"{i:<8} {reason:<16} {repr(content)}\")\n",
    "\n",
    "print(\"\\n\\u2139\\ufe0f The last chunk has finish_reason='stop' and empty content.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3C: Collecting Full Response While Streaming\n",
    "\n",
    "In production, you often need to **stream to the user AND store the complete response** — e.g., to save to a database or add to conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">Name 3 programming languages and one strength of each. Brief.</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming...\n",
      "\n",
      "Sure! Here are three programming languages along with one strength of each:\n",
      "\n",
      "1. **Python**: Easy to read and write, making it ideal for beginners and rapid prototyping.\n",
      "\n",
      "2. **JavaScript**: Highly versatile and the backbone of web development, enabling interactive and dynamic websites.\n",
      "\n",
      "3. **C++**: Offers fine-grained control over system resources, making it excellent for performance-critical applications like game development and system software.\n",
      "\n",
      "✅ Full response saved! Length: 450 characters\n",
      "   First 80 chars: Sure! Here are three programming languages along with one strength of each:\n",
      "\n",
      "1. ...\n"
     ]
    }
   ],
   "source": [
    "def stream_and_collect(messages, max_tokens=100, **kwargs):\n",
    "    \"\"\"Stream response to screen AND collect the full text.\"\"\"\n",
    "    stream = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        max_tokens=max_tokens,\n",
    "        stream=True,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    full_response = \"\"\n",
    "    for chunk in stream:\n",
    "        delta = chunk.choices[0].delta.content\n",
    "        if delta:\n",
    "            print(delta, end=\"\", flush=True)\n",
    "            full_response += delta\n",
    "\n",
    "    print()  # newline\n",
    "    return full_response\n",
    "\n",
    "\n",
    "# Use it — stream AND save\n",
    "messages = [{\"role\": \"user\", \"content\": \"Name 3 programming languages and one strength of each. Brief.\"}]\n",
    "\n",
    "show_messages(messages)\n",
    "print(\"Streaming...\\n\")\n",
    "saved = stream_and_collect(messages)\n",
    "\n",
    "print(f\"\\n\\u2705 Full response saved! Length: {len(saved)} characters\")\n",
    "print(f\"   First 80 chars: {saved[:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3D: Stream with Error Handling (Production Pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">What is Python? One sentence.</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is a high-level, interpreted programming language known for its readability and versatility, making it popular for various applications including web development, data analysis, artificial intelligence, and automation.\n",
      "\n",
      "✅ Got response: True\n"
     ]
    }
   ],
   "source": [
    "from openai import APIError, RateLimitError, APIConnectionError\n",
    "\n",
    "\n",
    "def stream_safe(messages, max_tokens=100):\n",
    "    \"\"\"Production-ready streaming with error handling.\"\"\"\n",
    "    try:\n",
    "        stream = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages,\n",
    "            max_tokens=max_tokens,\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "        full_response = \"\"\n",
    "        for chunk in stream:\n",
    "            delta = chunk.choices[0].delta.content\n",
    "            if delta:\n",
    "                print(delta, end=\"\", flush=True)\n",
    "                full_response += delta\n",
    "\n",
    "        print()\n",
    "        return full_response\n",
    "\n",
    "    except RateLimitError:\n",
    "        print(\"\\n\\u26a0\\ufe0f Rate limited! Wait and retry.\")\n",
    "    except APIConnectionError:\n",
    "        print(\"\\n\\u26a0\\ufe0f Connection failed! Check your internet.\")\n",
    "    except APIError as e:\n",
    "        print(f\"\\n\\u26a0\\ufe0f API Error: {e.message}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "# Test it\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is Python? One sentence.\"}]\n",
    "show_messages(messages)\n",
    "result = stream_safe(messages)\n",
    "print(f\"\\n\\u2705 Got response: {result is not None}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3E: Getting Token Usage in Streaming Mode\n",
    "\n",
    "By default, usage stats are **not available** during streaming. Pass `stream_options` to request them — they arrive in the final chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">What is gravity? One sentence.</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gravity is a fundamental force of nature that attracts two bodies with mass toward each other, influencing their motion and structure in the universe.\n",
      "\n",
      "ℹ️ Token usage (from final chunk):\n",
      "   Prompt:     14\n",
      "   Completion: 26\n",
      "   Total:      40\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"What is gravity? One sentence.\"}]\n",
    "show_messages(messages)\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages,\n",
    "    max_tokens=50,\n",
    "    stream=True,\n",
    "    stream_options={\"include_usage\": True}  # <-- request usage stats\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    delta = chunk.choices[0].delta.content if chunk.choices else None\n",
    "    if delta:\n",
    "        print(delta, end=\"\", flush=True)\n",
    "\n",
    "    # Usage arrives in the final chunk\n",
    "    if chunk.usage:\n",
    "        print(f\"\\n\\n\\u2139\\ufe0f Token usage (from final chunk):\")\n",
    "        print(f\"   Prompt:     {chunk.usage.prompt_tokens}\")\n",
    "        print(f\"   Completion: {chunk.usage.completion_tokens}\")\n",
    "        print(f\"   Total:      {chunk.usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to Use Streaming vs Normal\n",
    "\n",
    "| Use Case | Mode | Why |\n",
    "|----------|------|-----|\n",
    "| Chat interfaces | **Streaming** | Users see tokens appear in real time |\n",
    "| Backend processing | **Normal** | Simpler code, full response at once |\n",
    "| Long responses | **Streaming** | Avoids timeout, shows progress |\n",
    "| JSON extraction | **Normal** | Need complete JSON before parsing |\n",
    "| Voice assistants | **Streaming** | Start TTS while still generating |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Sandbox — Try It Yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #e74c3c;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#e74c3c;text-transform:uppercase;\">system</strong><br><span style=\"color:#ccc;\">You are a helpful assistant. Keep it brief.</span></div><div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">What makes Python popular?</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STREAMING]\n",
      "Python's popularity stems from several key factors:\n",
      "\n",
      "1. **Ease of Learning**: Its simple and readable syntax makes it accessible for beginners.\n",
      "2. **Versatility**: Python is used in various domains, including web development, data science, artificial intelligence, machine learning, and automation.\n",
      "3. **Large Community**: A strong community provides extensive resources, libraries, and frameworks (like Django,\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "#  SANDBOX - Edit and re-run!\n",
    "# ============================================================\n",
    "\n",
    "my_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant. Keep it brief.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What makes Python popular?\"}\n",
    "]\n",
    "\n",
    "use_streaming = True   # Toggle: True for streaming, False for normal\n",
    "my_max_tokens = 80\n",
    "\n",
    "# ============================================================\n",
    "\n",
    "show_messages(my_messages)\n",
    "\n",
    "if use_streaming:\n",
    "    print(\"\\n[STREAMING]\")\n",
    "    _ = stream_and_collect(my_messages, max_tokens=my_max_tokens)\n",
    "else:\n",
    "    print(\"\\n[NORMAL]\")\n",
    "    _ = chat(my_messages, max_tokens=my_max_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "| Concept | What to Remember |\n",
    "|---------|------------------|\n",
    "| **API Key** | Always load from `.env` — never hardcode. One key per project. |\n",
    "| **Client Setup** | `OpenAI()` reads `OPENAI_API_KEY` from environment automatically |\n",
    "| **Request** | Only `model` + `messages` are required; everything else is optional |\n",
    "| **Messages** | List of `{role, content}` dicts — system/user/assistant |\n",
    "| **Response** | Contains `choices[0].message.content`, `finish_reason`, and `usage` |\n",
    "| **finish_reason** | `stop` = natural end, `length` = cut off, `tool_calls` = function call |\n",
    "| **Multi-turn** | No built-in memory — resend full history every time |\n",
    "| **Streaming** | Add `stream=True` — tokens arrive chunk by chunk |\n",
    "| **Stream Usage** | Pass `stream_options={\"include_usage\": True}` for token counts |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
