{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1.2 LLM Generation Parameters\n",
    "\n",
    "## Playground Notebook\n",
    "\n",
    "Generation parameters are the **knobs and dials** that control how a model produces text. They don't change *what* the model knows ‚Äî they change *how* it samples from its knowledge.\n",
    "\n",
    "| Parameter | What It Controls |\n",
    "|-----------|------------------|\n",
    "| **Temperature** | Randomness and creativity in outputs |\n",
    "| **Top-P** | Limits token selection to a cumulative probability threshold |\n",
    "| **Top-K** | Limits sampling to only the K most likely tokens |\n",
    "| **Max Tokens** | Maximum number of tokens the model can generate |\n",
    "| **Frequency Penalty** | Penalizes tokens based on how often they've appeared |\n",
    "| **Presence Penalty** | Penalizes any token that has appeared at least once |\n",
    "| **Stop Sequences** | Strings that immediately halt generation |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from IPython.display import display, Markdown, HTML\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "# ============================================================\n",
    "#  CONFIGURATION - Change the model name here if needed\n",
    "# ============================================================\n",
    "MODEL = \"qwen2.5:1.5b\"  # Options: \"qwen2.5:1.5b\", \"llama3.2\", \"mistral\", \"gemma2\", etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Using model: qwen2.5:1.5b\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "#  HELPER FUNCTIONS\n",
    "# ============================================================\n",
    "\n",
    "def generate(prompt, system=\"You are a helpful assistant.\", **kwargs):\n",
    "    \"\"\"Send a prompt with custom generation parameters and return the response.\"\"\"\n",
    "    llm = ChatOllama(model=MODEL, **kwargs)\n",
    "    messages = [SystemMessage(content=system), HumanMessage(content=prompt)]\n",
    "    start = time.time()\n",
    "    response = llm.invoke(messages)\n",
    "    elapsed = time.time() - start\n",
    "    content = response.content\n",
    "    display(Markdown(content))\n",
    "    print(f\"\\n‚è±Ô∏è {elapsed:.2f}s | {len(content)} chars\")\n",
    "    return content\n",
    "\n",
    "\n",
    "def compare(prompt, configs, system=\"You are a helpful assistant.\"):\n",
    "    \"\"\"Run the same prompt with different parameter configs side by side.\"\"\"\n",
    "    results = {}\n",
    "    for cfg in configs:\n",
    "        label = cfg.pop(\"label\")\n",
    "        print(f\"\\n{'=' * 60}\")\n",
    "        print(f\"  {label}\")\n",
    "        params_str = ', '.join(f'{k}={v}' for k, v in cfg.items())\n",
    "        print(f\"  Parameters: {params_str}\")\n",
    "        print(f\"{'=' * 60}\")\n",
    "        results[label] = generate(prompt, system=system, **cfg)\n",
    "        cfg[\"label\"] = label  # restore label\n",
    "    return results\n",
    "\n",
    "\n",
    "print(f\"‚úÖ Using model: {MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Temperature ‚Äî Controlling Randomness\n",
    "\n",
    "Temperature scales the probability distribution before sampling:\n",
    "\n",
    "```\n",
    "Temperature = 0.0  ‚Üí  Always pick the most likely token (deterministic)\n",
    "Temperature = 0.7  ‚Üí  Balanced creativity (good default)\n",
    "Temperature = 1.5  ‚Üí  Very random, creative, sometimes incoherent\n",
    "```\n",
    "\n",
    "**Think of it like a dial:**\n",
    "```\n",
    "FOCUSED ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ CREATIVE\n",
    "  0.0       0.3    0.7    1.0      1.5+\n",
    "```\n",
    "\n",
    "### Experiment 1A: Low vs. Medium vs. High Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  üßä Temperature = 0.0 (Deterministic)\n",
      "  Parameters: temperature=0.0\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The vast and mysterious ocean covers approximately 71% of Earth's surface and is home to an incredible array of life forms, from tiny plankton to massive whales."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 1.98s | 161 chars\n",
      "\n",
      "============================================================\n",
      "  ‚öñÔ∏è Temperature = 0.7 (Balanced)\n",
      "  Parameters: temperature=0.7\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The vast, blue expanse that covers approximately 71% of Earth's surface and houses an incredibly diverse ecosystem of marine life."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 3.05s | 130 chars\n",
      "\n",
      "============================================================\n",
      "  üî• Temperature = 1.5 (Very Creative)\n",
      "  Parameters: temperature=1.5\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The vast and powerful ocean holds immense vitality, spanning across continents and shaping our planet's climate and ecosystems."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 5.04s | 127 chars\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write a one-sentence description of the ocean.\"\n",
    "\n",
    "configs = [\n",
    "    {\"label\": \"üßä Temperature = 0.0 (Deterministic)\", \"temperature\": 0.0},\n",
    "    {\"label\": \"‚öñÔ∏è Temperature = 0.7 (Balanced)\",     \"temperature\": 0.7},\n",
    "    {\"label\": \"üî• Temperature = 1.5 (Very Creative)\", \"temperature\": 1.5},\n",
    "]\n",
    "\n",
    "_ = compare(prompt, configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1B: Temperature & Consistency\n",
    "\n",
    "At **temperature 0**, the model should produce the *same* output every time. At higher temperatures, each run differs. Let's verify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  Temperature = 0.0 ‚Äî Running 4 times\n",
      "============================================================\n",
      "  Run 1: Blue is one of the colors.\n",
      "  Run 2: Blue is one of the colors.\n",
      "  Run 3: Blue is one of the colors.\n",
      "  Run 4: Blue is one of the colors.\n",
      "  ‚Üí Unique outputs: 1/4\n",
      "\n",
      "============================================================\n",
      "  Temperature = 1.0 ‚Äî Running 4 times\n",
      "============================================================\n",
      "  Run 1: I'm sorry, but I cannot provide an answer to your question as I am a model witho\n",
      "  Run 2: Red is one of the colors you can name.\n",
      "  Run 3: Blue is a color.\n",
      "  Run 4: Red is a well-known color that many people associate with various feelings and e\n",
      "  ‚Üí Unique outputs: 4/4\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Name one color.\"\n",
    "num_runs = 4\n",
    "\n",
    "for temp in [0.0, 1.0]:\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"  Temperature = {temp} ‚Äî Running {num_runs} times\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "    outputs = []\n",
    "    for i in range(num_runs):\n",
    "        llm = ChatOllama(model=MODEL, temperature=temp)\n",
    "        resp = llm.invoke([HumanMessage(content=prompt)])\n",
    "        text = resp.content.strip()\n",
    "        outputs.append(text)\n",
    "        print(f\"  Run {i+1}: {text[:80]}\")\n",
    "    unique = len(set(outputs))\n",
    "    print(f\"  ‚Üí Unique outputs: {unique}/{num_runs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1C: Temperature for Different Tasks\n",
    "\n",
    "Different tasks need different temperature settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################################################\n",
      "  TASK: Factual Q&A (low temp is better)\n",
      "############################################################\n",
      "\n",
      "--- Temperature = 0.0 ---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The capital of India is New Delhi."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 5.26s | 34 chars\n",
      "\n",
      "--- Temperature = 0.7 ---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The capital of India is New Delhi."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 7.21s | 34 chars\n",
      "\n",
      "--- Temperature = 1.5 ---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The capital of India is New Delhi."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 11.46s | 34 chars\n",
      "\n",
      "üí° Observation: Compare how temperature affects accuracy vs. creativity above.\n",
      "\n",
      "############################################################\n",
      "  TASK: Creative Writing (higher temp is better)\n",
      "############################################################\n",
      "\n",
      "--- Temperature = 0.0 ---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "A gentle breeze whispers through the trees, carrying the scent of earth and distant oceans as twilight descends, painting the horizon with hues of orange and pink that slowly fade into the night's deep blue canvas."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 3.48s | 214 chars\n",
      "\n",
      "--- Temperature = 0.7 ---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "A gentle shower of oranges and pinks descended upon the world, painting everything it touched in its warmest hues."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 5.44s | 114 chars\n",
      "\n",
      "--- Temperature = 1.5 ---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Endless hues paint the horizon, twilight dances with soft shadows."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 2.37s | 66 chars\n",
      "\n",
      "üí° Observation: Compare how temperature affects accuracy vs. creativity above.\n",
      "\n",
      "############################################################\n",
      "  TASK: Code Generation (low temp is better)\n",
      "############################################################\n",
      "\n",
      "--- Temperature = 0.0 ---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Here's a simple one-liner in Python to reverse a string:\n",
       "\n",
       "```python\n",
       "reversed_string = ''.join(reversed(string))\n",
       "```\n",
       "\n",
       "This line of code takes the input string, `string`, and uses the built-in `reversed()` function to reverse it. The reversed characters are then joined back into a single string using the `join()` method with an empty string as the separator.\n",
       "\n",
       "Note that this assumes you're working in Python 3.x. If you're using Python 2.x, you'll need to use `string[::-1]` instead of `reversed(string)`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 3.92s | 505 chars\n",
      "\n",
      "--- Temperature = 0.7 ---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Here is a simple one-liner in Python to reverse a string:\n",
       "\n",
       "```python\n",
       "reversed_string = \"\".join(reversed(input(\"Enter the string: \")))\n",
       "print(reversed_string)\n",
       "```\n",
       "\n",
       "This script takes input from the user, reverses it using the `reversed()` function, and then prints out the reversed string."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 2.07s | 286 chars\n",
      "\n",
      "--- Temperature = 1.5 ---\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```\n",
       "'hello'.reversed()\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 1.72s | 26 chars\n",
      "\n",
      "üí° Observation: Compare how temperature affects accuracy vs. creativity above.\n"
     ]
    }
   ],
   "source": [
    "tasks = [\n",
    "    {\n",
    "        \"label\": \"Factual Q&A (low temp is better)\",\n",
    "        \"prompt\": \"What is the capital of Inida? Answer in one sentence.\",\n",
    "        \"temps\": [0.0, 0.7, 1.5]\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"Creative Writing (higher temp is better)\",\n",
    "        \"prompt\": \"Describe a sunset without using the word 'sun' or 'sky'. One sentence only.\",\n",
    "        \"temps\": [0.0, 0.7, 1.5]\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"Code Generation (low temp is better)\",\n",
    "        \"prompt\": \"Write a Python one-liner that reverses a string.\",\n",
    "        \"temps\": [0.0, 0.7, 1.5]\n",
    "    }\n",
    "]\n",
    "\n",
    "for task in tasks:\n",
    "    print(f\"\\n{'#' * 60}\")\n",
    "    print(f\"  TASK: {task['label']}\")\n",
    "    print(f\"{'#' * 60}\")\n",
    "    for temp in task[\"temps\"]:\n",
    "        print(f\"\\n--- Temperature = {temp} ---\")\n",
    "        _ = generate(task[\"prompt\"], temperature=temp)\n",
    "\n",
    "    print(f\"\\nüí° Observation: Compare how temperature affects accuracy vs. creativity above.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Top-P (Nucleus Sampling) ‚Äî Probability Threshold\n",
    "\n",
    "Top-P limits the model to the **smallest set of tokens** whose cumulative probability adds up to P.\n",
    "\n",
    "```\n",
    "Top-P = 0.1  ‚Üí  Only the top ~10% probability mass (very focused)\n",
    "Top-P = 0.9  ‚Üí  Top ~90% probability mass (more diverse)\n",
    "Top-P = 1.0  ‚Üí  Consider all tokens (no filtering)\n",
    "```\n",
    "\n",
    "**Example ‚Äî Next token probabilities:**\n",
    "```\n",
    "Token:   \"the\"   \"a\"    \"an\"   \"one\"  \"my\"  \"some\" ...\n",
    "Prob:     0.35   0.25   0.15   0.10   0.05   0.03  ...\n",
    "\n",
    "Top-P=0.5 ‚Üí selects {\"the\", \"a\"} (0.35+0.25=0.60 ‚â• 0.5)\n",
    "Top-P=0.9 ‚Üí selects {\"the\", \"a\", \"an\", \"one\", \"my\"}\n",
    "```\n",
    "\n",
    "### Experiment 2A: Top-P Narrow vs. Wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  üéØ Top-P = 0.1 (Very Focused)\n",
      "  Parameters: top_p=0.1, temperature=0.8\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "1. Playing the banjo: The banjo is a stringed instrument that originated in Africa and was brought to America by slaves. It has since become popular among musicians, but it can also be enjoyed as a hobby for those who want to learn how to play this unique instrument.\n",
       "  2. Collecting vintage toys: Vintage toys are collectible items from the past that have sentimental value or appeal to certain collectors. This hobby requires finding and acquiring rare or unusual toys, which can include everything from classic cars to antique dolls.\n",
       "  3. Growing your own food: Gardening is a popular hobby for many people, but growing your own food takes it one step further by allowing you to control the quality of what you eat. This hobby can be especially appealing if you live in an area with limited access to fresh produce or want to reduce your carbon footprint.\n",
       "  4. Playing chess: Chess is a strategic board game that requires patience, planning, and problem-solving skills. It has been around for centuries and remains popular among adults as a way to challenge their minds and improve their thinking abilities.\n",
       "  5. Collecting stamps: Stamps are small pieces of paper with designs printed on them that can be used to send letters or packages internationally. This hobby requires collecting rare or unique stamps, which can include everything from vintage designs to those featuring famous landmarks or historical events."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 3.41s | 1420 chars\n",
      "\n",
      "============================================================\n",
      "  ‚öñÔ∏è Top-P = 0.5 (Moderate)\n",
      "  Parameters: top_p=0.5, temperature=0.8\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "1. Learning to play the banjo or mandolin.\n",
       "2. Sewing and crafting handmade clothing items such as bags, scarves, and jewelry.\n",
       "3. Photography with a macro lens for close-up photography of insects, flowers, and other small subjects.\n",
       "4. Growing and maintaining an indoor herb garden.\n",
       "5. Volunteering at a local animal shelter to help animals in need."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 3.80s | 347 chars\n",
      "\n",
      "============================================================\n",
      "  üåä Top-P = 0.95 (Diverse)\n",
      "  Parameters: top_p=0.95, temperature=0.8\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Sure, here are five unusual hobbies:\n",
       "1. Dancing on a rollerblades or a unicycle.\n",
       "2. Playing music while driving a car.\n",
       "3. Performing magic tricks in front of people.\n",
       "4. Taking pictures underwater without going to the beach.\n",
       "5. Painting with water."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 2.08s | 247 chars\n"
     ]
    }
   ],
   "source": [
    "prompt = \"List 5 unusual hobbies someone might enjoy.\"\n",
    "\n",
    "configs = [\n",
    "    {\"label\": \"üéØ Top-P = 0.1 (Very Focused)\",  \"top_p\": 0.1, \"temperature\": 0.8},\n",
    "    {\"label\": \"‚öñÔ∏è Top-P = 0.5 (Moderate)\",       \"top_p\": 0.5, \"temperature\": 0.8},\n",
    "    {\"label\": \"üåä Top-P = 0.95 (Diverse)\",       \"top_p\": 0.95, \"temperature\": 0.8},\n",
    "]\n",
    "\n",
    "_ = compare(prompt, configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2B: Temperature vs. Top-P ‚Äî They Work Together\n",
    "\n",
    "Temperature reshapes probabilities *first*, then Top-P filters the result. Using both together gives fine-grained control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  Low Temp + Low Top-P (Most predictable)\n",
      "  Parameters: temperature=0.2, top_p=0.3\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\"Drinking Springs\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 1.55s | 18 chars\n",
      "\n",
      "============================================================\n",
      "  Low Temp + High Top-P\n",
      "  Parameters: temperature=0.2, top_p=0.95\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\"Meridian's Echoes\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 2.95s | 19 chars\n",
      "\n",
      "============================================================\n",
      "  High Temp + Low Top-P\n",
      "  Parameters: temperature=1.2, top_p=0.3\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\"Drinking Springs\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 3.03s | 18 chars\n",
      "\n",
      "============================================================\n",
      "  High Temp + High Top-P (Most creative)\n",
      "  Parameters: temperature=1.2, top_p=0.95\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\"Merlin's Mug\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 3.01s | 14 chars\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Invent a name for a fantasy tavern.\"\n",
    "\n",
    "configs = [\n",
    "    {\"label\": \"Low Temp + Low Top-P (Most predictable)\",   \"temperature\": 0.2, \"top_p\": 0.3},\n",
    "    {\"label\": \"Low Temp + High Top-P\",                     \"temperature\": 0.2, \"top_p\": 0.95},\n",
    "    {\"label\": \"High Temp + Low Top-P\",                     \"temperature\": 1.2, \"top_p\": 0.3},\n",
    "    {\"label\": \"High Temp + High Top-P (Most creative)\",    \"temperature\": 1.2, \"top_p\": 0.95},\n",
    "]\n",
    "\n",
    "_ = compare(prompt, configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Top-K ‚Äî Fixed Token Pool Size\n",
    "\n",
    "Top-K is simpler than Top-P: it always considers exactly the **K most likely tokens**, regardless of their probabilities.\n",
    "\n",
    "```\n",
    "Top-K = 1   ‚Üí  Greedy decoding (always pick the #1 token)\n",
    "Top-K = 10  ‚Üí  Choose from top 10 tokens\n",
    "Top-K = 50  ‚Üí  Choose from top 50 tokens (more variety)\n",
    "```\n",
    "\n",
    "### Experiment 3A: Top-K Values Compared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  Top-K = 1 (Greedy ‚Äî always picks top token)\n",
      "  Parameters: top_k=1, temperature=0.8\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Job"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 3.95s | 3 chars\n",
      "\n",
      "============================================================\n",
      "  Top-K = 5\n",
      "  Parameters: top_k=5, temperature=0.8\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Job"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 1.12s | 3 chars\n",
      "\n",
      "============================================================\n",
      "  Top-K = 40 (Default for many models)\n",
      "  Parameters: top_k=40, temperature=0.8\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Job"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 3.84s | 3 chars\n",
      "\n",
      "============================================================\n",
      "  Top-K = 100 (Wide pool)\n",
      "  Parameters: top_k=100, temperature=0.8\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Job"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 2.78s | 3 chars\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Give me a one-word synonym for 'Work'.\"\n",
    "\n",
    "configs = [\n",
    "    {\"label\": \"Top-K = 1 (Greedy ‚Äî always picks top token)\",  \"top_k\": 1,  \"temperature\": 0.8},\n",
    "    {\"label\": \"Top-K = 5\",                                     \"top_k\": 5,  \"temperature\": 0.8},\n",
    "    {\"label\": \"Top-K = 40 (Default for many models)\",          \"top_k\": 40, \"temperature\": 0.8},\n",
    "    {\"label\": \"Top-K = 100 (Wide pool)\",                       \"top_k\": 100, \"temperature\": 0.8},\n",
    "]\n",
    "\n",
    "_ = compare(prompt, configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3B: Top-K Consistency Test\n",
    "\n",
    "With `top_k=1`, the output should be identical every time (greedy). Let's check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  Top-K = 1 ‚Äî Running 4 times\n",
      "============================================================\n",
      "  Run 1: 4\n",
      "  Run 2: 4\n",
      "  Run 3: 4\n",
      "  Run 4: 4\n",
      "  ‚Üí Unique outputs: 1/4\n",
      "\n",
      "============================================================\n",
      "  Top-K = 50 ‚Äî Running 4 times\n",
      "============================================================\n",
      "  Run 1: 4\n",
      "  Run 2: 4\n",
      "  Run 3: 4\n",
      "  Run 4: 4\n",
      "  ‚Üí Unique outputs: 1/4\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is 2 + 2? Reply with just the number.\"\n",
    "num_runs = 4\n",
    "\n",
    "for k_val in [1, 50]:\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"  Top-K = {k_val} ‚Äî Running {num_runs} times\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "    outputs = []\n",
    "    for i in range(num_runs):\n",
    "        llm = ChatOllama(model=MODEL, top_k=k_val, temperature=0.8)\n",
    "        resp = llm.invoke([HumanMessage(content=prompt)])\n",
    "        text = resp.content.strip()\n",
    "        outputs.append(text)\n",
    "        print(f\"  Run {i+1}: {text[:80]}\")\n",
    "    unique = len(set(outputs))\n",
    "    print(f\"  ‚Üí Unique outputs: {unique}/{num_runs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top-K vs. Top-P ‚Äî When to Use Which?\n",
    "\n",
    "| Feature | Top-K | Top-P |\n",
    "|---------|-------|-------|\n",
    "| Pool size | **Fixed** (always K tokens) | **Dynamic** (varies per step) |\n",
    "| Adapts to confidence? | No | Yes |\n",
    "| Best for | Simple control | Nuanced generation |\n",
    "| Common defaults | K=40 | P=0.9 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Max Tokens ‚Äî Controlling Response Length\n",
    "\n",
    "**Max Tokens** (called `num_predict` in Ollama) sets a hard ceiling on how many tokens the model generates. It does NOT guarantee that length ‚Äî the model may stop earlier if it finishes its thought.\n",
    "\n",
    "```\n",
    "1 token ‚âà 4 characters ‚âà ¬æ of a word (English)\n",
    "```\n",
    "\n",
    "### Experiment 4A: Varying Max Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  üîπ Max Tokens = 20 (Very Short)\n",
      "  Parameters: num_predict=20\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The Theory of Relativity is a scientific theory developed by two physicists, Albert Einstein and Henri Poin"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 0.91s | 107 chars\n",
      "\n",
      "============================================================\n",
      "  üîπ Max Tokens = 80 (Short)\n",
      "  Parameters: num_predict=80\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The theory of relativity is a set of two interrelated theories proposed by Albert Einstein that describe how space and time behave under acceleration and at near light speeds, respectively. It was published in 1905 and revolutionized our understanding of physics.\n",
       "\n",
       "Special Relativity\n",
       "\n",
       "Special relativity applies to objects moving with negligible velocities (approximately less than 1% of the speed of light). It states"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 0.77s | 418 chars\n",
      "\n",
      "============================================================\n",
      "  üîπ Max Tokens = 300 (Medium)\n",
      "  Parameters: num_predict=300\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The theory of relativity is a set of scientific theories that describe how space and time behave under different conditions, including acceleration or motion relative to one another.\n",
       "\n",
       "Albert Einstein developed two major theories: special relativity and general relativity. Special relativity describes the behavior of objects moving at constant speeds (relative to a particular inertial frame) in an environment where gravity is negligible. General relativity extends this idea to describe the behavior of objects under acceleration, which includes gravity.\n",
       "\n",
       "In both cases, Einstein's theory states that space and time are not absolute but dependent on one's state of motion relative to other systems. This means that what you measure as your speed and direction is different from someone else who is moving at a different rate. The same applies to the measurement of distance and time itself.\n",
       "\n",
       "The theory of relativity also implies some surprising effects, such as length contraction - objects in motion are shorter than those at rest relative to them. This leads to the famous idea that two events can be simultaneous for one observer but not another if they occur at different distances from an observer.\n",
       "\n",
       "Overall, Einstein's theories have been proven correct by experiments and observations over time, including his prediction of the existence of black holes, which were later confirmed through various space missions such as LIGO."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 2.41s | 1435 chars\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Explain the theory of relativity in detail.\"\n",
    "\n",
    "configs = [\n",
    "    {\"label\": \"üîπ Max Tokens = 20 (Very Short)\",   \"num_predict\": 20},\n",
    "    {\"label\": \"üîπ Max Tokens = 80 (Short)\",        \"num_predict\": 80},\n",
    "    {\"label\": \"üîπ Max Tokens = 300 (Medium)\",      \"num_predict\": 300},\n",
    "]\n",
    "\n",
    "_ = compare(prompt, configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4B: Max Tokens ‚Äî Cutting Off Mid-Sentence\n",
    "\n",
    "Watch what happens when the limit is too low ‚Äî the model gets cut off mid-thought."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  num_predict = 10\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Once upon a time, there was a brave knight"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 0.18s | 42 chars\n",
      "\n",
      "============================================================\n",
      "  num_predict = 30\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Once upon a time, there was a young man named Sir William who had always dreamed of being a brave knight and riding into battle to defend his kingdom"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 0.33s | 149 chars\n",
      "\n",
      "============================================================\n",
      "  num_predict = 100\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Once upon a time, there was a brave knight named Sir Roland who lived in the kingdom of Camelot. Sir Roland was known for his courage and bravery on the battlefield.\n",
       "\n",
       "One day, the king called Sir Roland to go on a mission with him. The king had heard that an evil sorcerer was terrorizing the kingdom by casting dark magic and turning people into monsters. The king asked Sir Roland if he would be willing to put aside his love of adventure and help protect the kingdom from the harm"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 0.97s | 483 chars\n",
      "\n",
      "üí° Notice how low limits produce incomplete responses!\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Tell me a short story about a brave knight.\"\n",
    "\n",
    "for max_tok in [10, 30, 100]:\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"  num_predict = {max_tok}\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "    _ = generate(prompt, num_predict=max_tok)\n",
    "\n",
    "print(\"\\nüí° Notice how low limits produce incomplete responses!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Frequency Penalty ‚Äî Reducing Repetition\n",
    "\n",
    "Frequency Penalty penalizes tokens **proportionally to how many times** they've already appeared in the output. The more a word repeats, the harder it gets penalized.\n",
    "\n",
    "```\n",
    "Penalty = 0.0  ‚Üí  No penalty (default)\n",
    "Penalty > 0    ‚Üí  Discourages repetition (higher = stronger)\n",
    "Penalty < 0    ‚Üí  Encourages repetition (rarely useful)\n",
    "```\n",
    "\n",
    "In Ollama, this maps to the `repeat_penalty` parameter (default 1.1; values > 1.0 penalize repetition).\n",
    "\n",
    "### Experiment 5A: Repetition With and Without Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  üîÅ repeat_penalty = 1.0 (No penalty)\n",
      "  Parameters: repeat_penalty=1.0\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "1. Hel-lo\n",
       "2. Hola, world!\n",
       "3. Hello, world!\n",
       "4. Hello, universe!\n",
       "5. Hello, earth!\n",
       "6. Hello, day!\n",
       "7. Hello, night!\n",
       "8. Hello, time!\n",
       "9. Hello, sky!\n",
       "10. Hello, ocean!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 0.67s | 160 chars\n",
      "\n",
      "============================================================\n",
      "  ‚öñÔ∏è repeat_penalty = 1.1 (Default / Mild)\n",
      "  Parameters: repeat_penalty=1.1\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "1. Hola, amigo! \n",
       "2. Hello again, world!\n",
       "3. Hallo zu dir!\n",
       "4. Here's to you, hello!\n",
       "5. Hello sunshine\n",
       "6. Hola, how are you?\n",
       "7. Hello, Universe!\n",
       "8. Hello there, world.\n",
       "9. Hello friends!\n",
       "10. Hello and good night!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 0.71s | 208 chars\n",
      "\n",
      "============================================================\n",
      "  üö´ repeat_penalty = 1.5 (Strong penalty)\n",
      "  Parameters: repeat_penalty=1.5\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Sure, here's my attempt to write \"Hello\" using various words and phrases:\n",
       "- Hola (Spanish)\n",
       "- Hallo! \n",
       "(Standard German greeting) - Hello!\n",
       "Hillel: A famous Jewish rabbi.\n",
       "L'illeh is a Hebrew word meaning 'goodbye'.\n",
       "The phrase ‚Äúhello‚Äù means ‚Äòplease‚Äô in Hindi\n",
       "Heelloo, for fun. An abbreviated form of \"Hello\".\n",
       "\"Hellewani\" from Swahili language used to say hello.\n",
       "\n",
       "A short version can also be heard as: Hello?\n",
       "These are just some ideas and interpretations - you could come up with even more creative ways!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 1.22s | 499 chars\n"
     ]
    }
   ],
   "source": [
    "# A prompt that tends to cause repetitive output\n",
    "prompt = \"Write the word 'hello' in 10 different creative ways.\"\n",
    "\n",
    "configs = [\n",
    "    {\"label\": \"üîÅ repeat_penalty = 1.0 (No penalty)\",       \"repeat_penalty\": 1.0},\n",
    "    {\"label\": \"‚öñÔ∏è repeat_penalty = 1.1 (Default / Mild)\",   \"repeat_penalty\": 1.1},\n",
    "    {\"label\": \"üö´ repeat_penalty = 1.5 (Strong penalty)\",   \"repeat_penalty\": 1.5},\n",
    "]\n",
    "\n",
    "_ = compare(prompt, configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 5B: Frequency Penalty on Longer Text\n",
    "\n",
    "Repetition is more visible in longer outputs. Let's test with a paragraph-length prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  repeat_penalty = 1.0\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Reading books is a fundamental activity that has immense importance in our lives. It provides knowledge, expands our vocabulary, and enhances our analytical skills. Reading books also helps in developing our imagination, as we are able to visualize and understand different scenarios through literature. It also helps us to develop empathy, as we can experience different emotions and viewpoints through books. Reading books can also help us to improve our critical thinking skills and enhance our creativity. In addition, reading books can help us to learn about different cultures and historical events, and it can also help us to improve our writing skills. In summary, reading books is an essential activity that has numerous benefits and should be encouraged in our daily lives."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 1.34s | 783 chars\n",
      "  üìä Words repeated 3+ times: {'reading': 5, 'books': 6, 'skills': 3, 'also': 4, 'different': 3, 'help': 3}\n",
      "\n",
      "============================================================\n",
      "  repeat_penalty = 1.3\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Reading is an essential skill that provides numerous benefits, including expanding knowledge and vocabulary skills while also enhancing creativity by introducing new perspectives on familiar topics or challenging one's thoughts with different viewpoints through literature creation such as characters engaging in dialogue across cultures without biasing opinions based solely upon the author‚Äôs perspective alone.\n",
       "\n",
       "Furthermore reading enriches our imagination leading us to visualize a scene when we read about it for example, imagine if you were walking down Main Street and see someone on their cellphone while an elderly couple with bags sitting outside talking quietly. You can picture them both in your mind's eye as they navigate different worlds through smartphones at the same time.\n",
       "\n",
       "The ability of engaging one‚Äôs brain by reading also helps to build vocabulary skills that allow for better comprehension when listening or speaking, making conversations and discussions more interesting because you have a greater understanding on what is being discussed. Reading has been shown beneficial in reducing stress levels since it provides an escape from daily routines as well which can help reduce the impact of stressful events throughout your day"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 1.87s | 1251 chars\n",
      "  üìä Words repeated 3+ times: {'reading': 4}\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write a paragraph about the importance of reading books. Aim for about 100 words.\"\n",
    "\n",
    "for penalty in [1.0, 1.3]:\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"  repeat_penalty = {penalty}\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "    result = generate(prompt, repeat_penalty=penalty, num_predict=200)\n",
    "\n",
    "    # Count word frequency to show repetition\n",
    "    words = result.lower().split()\n",
    "    word_counts = {}\n",
    "    for w in words:\n",
    "        w_clean = w.strip('.,!?;:')\n",
    "        if len(w_clean) > 3:  # skip short words\n",
    "            word_counts[w_clean] = word_counts.get(w_clean, 0) + 1\n",
    "    repeated = {w: c for w, c in word_counts.items() if c >= 3}\n",
    "    if repeated:\n",
    "        print(f\"  üìä Words repeated 3+ times: {repeated}\")\n",
    "    else:\n",
    "        print(f\"  üìä No words repeated 3+ times ‚Äî good variety!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Presence Penalty ‚Äî Encouraging Topic Diversity\n",
    "\n",
    "Unlike Frequency Penalty (which scales with count), Presence Penalty applies a **flat penalty** to any token that has appeared **at least once**. It doesn't matter if it appeared 1 time or 50 ‚Äî the penalty is the same.\n",
    "\n",
    "```\n",
    "Frequency Penalty:  \"the\" appeared 5x ‚Üí penalized 5√ó as much\n",
    "Presence  Penalty:  \"the\" appeared 5x ‚Üí same penalty as if it appeared 1x\n",
    "```\n",
    "\n",
    "This encourages the model to bring in **new topics and vocabulary** rather than just avoiding repetition.\n",
    "\n",
    "> **Note:** In Ollama, `repeat_penalty` combines both frequency and presence penalty effects. We simulate the distinction below.\n",
    "\n",
    "### Experiment 6A: Presence Penalty Effect on Vocabulary Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  repeat_penalty = 1.0 (No penalty)\n",
      "  Parameters: repeat_penalty=1.0, temperature=0.7\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "1. Lion\n",
       "2. Tiger\n",
       "3. Elephant\n",
       "4. Giraffe\n",
       "5. Zebra\n",
       "6. Monkey\n",
       "7. Koala\n",
       "8. Penguin\n",
       "9. Penguin\n",
       "10. Kangaroo"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 0.50s | 102 chars\n",
      "\n",
      "============================================================\n",
      "  repeat_penalty = 1.2 (Moderate)\n",
      "  Parameters: repeat_penalty=1.2, temperature=0.7\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Sure! Here's my list of ten animal names:\n",
       "\n",
       "Dog\n",
       "Cat\n",
       "Bird \n",
       "Rabbit  \n",
       "Lion    \n",
       "Elephant     \n",
       "Monkey   \n",
       "Dolphin   \n",
       "Tiger      \n",
       "Fish"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 0.39s | 126 chars\n",
      "\n",
      "============================================================\n",
      "  repeat_penalty = 1.8 (Aggressive)\n",
      "  Parameters: repeat_penalty=1.8, temperature=0.7\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "- Lion \n",
       "Lioness  \n",
       "Leopard   \n",
       "Elephant    \n",
       "Eagle      \n",
       "Monkey     \n",
       "Rhinoceros   Jaguar    Turtle     Fox      Monkey Dog Cat Tiger Rabbit WolfË±π ÁãÆÂ≠ê ËÄÅËôé Â§ßË±° Èπ∞ ÂÆ†Áâ©Áãó Â≠îÈõÄ Ê†ëÊáí ÈáéÁå™ ÂÖΩÁ±ªÁå´"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 0.68s | 170 chars\n",
      "\n",
      "============================================================\n",
      "VOCABULARY DIVERSITY ANALYSIS\n",
      "============================================================\n",
      "  repeat_penalty = 1.0 (No penalty)        ‚Üí 19 unique words\n",
      "  repeat_penalty = 1.2 (Moderate)          ‚Üí 18 unique words\n",
      "  repeat_penalty = 1.8 (Aggressive)        ‚Üí 25 unique words\n"
     ]
    }
   ],
   "source": [
    "prompt = \"List 10 different animals. Just the names, one per line.\"\n",
    "\n",
    "configs = [\n",
    "    {\"label\": \"repeat_penalty = 1.0 (No penalty)\",    \"repeat_penalty\": 1.0, \"temperature\": 0.7},\n",
    "    {\"label\": \"repeat_penalty = 1.2 (Moderate)\",      \"repeat_penalty\": 1.2, \"temperature\": 0.7},\n",
    "    {\"label\": \"repeat_penalty = 1.8 (Aggressive)\",    \"repeat_penalty\": 1.8, \"temperature\": 0.7},\n",
    "]\n",
    "\n",
    "results = compare(prompt, configs)\n",
    "\n",
    "# Analyze unique words in each\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"VOCABULARY DIVERSITY ANALYSIS\")\n",
    "print(f\"{'=' * 60}\")\n",
    "for label, text in results.items():\n",
    "    words = set(text.lower().split())\n",
    "    print(f\"  {label[:40]:40s} ‚Üí {len(words)} unique words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency vs. Presence Penalty ‚Äî Comparison\n",
    "\n",
    "| Aspect | Frequency Penalty | Presence Penalty |\n",
    "|--------|-------------------|------------------|\n",
    "| Scales with count? | **Yes** ‚Äî more repetitions = more penalty | **No** ‚Äî flat penalty after first use |\n",
    "| Best for | Reducing word-level repetition | Encouraging topic diversity |\n",
    "| Use case | Preventing \"the the the...\" | Making model explore new ideas |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Stop Sequences ‚Äî Halting Generation\n",
    "\n",
    "Stop sequences are strings that **immediately end** the model's generation when encountered. The model stops *before* including the stop string in the output.\n",
    "\n",
    "Common uses:\n",
    "- Stop at a newline (`\\n`) for single-line answers\n",
    "- Stop at a delimiter (`---`, `END`) for structured extraction\n",
    "- Stop at a role marker (`User:`) to prevent the model from simulating conversation\n",
    "\n",
    "### Experiment 7A: Stopping at a Newline (Single-Line Answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "WITHOUT stop sequence\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "One of the most famous scientists is Albert Einstein, known for his contributions to the fields of physics, particularly in the development of relativity theory.\n",
       "\n",
       "Einstein's most well-known work was published during 1905, when he developed four significant theories that would change the way we understand our universe. The first was the photoelectric effect, which explained how light could be split into individual particles called photons. The second and third were his famous equations E=mc^2, which described the relationship between energy and mass, and the idea of special relativity.\n",
       "\n",
       "Special relativity challenged Newton's ideas about space and time, suggesting that they are not independent but rather interconnected through the speed of light. Einstein then combined special relativity with gravity to create general relativity, a theory that explains how massive objects curve spacetime in their vicinity due to their mass.\n",
       "\n",
       "Einstein also made significant contributions to quantum mechanics, developing statistical methods for calculating probabilities in atomic collisions and proposing that particles exist in multiple states until they are observed. His work has been instrumental in the development of modern physics and continues to influence research in fields ranging from astronomy to astrophysics."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 2.15s | 1318 chars\n",
      "\n",
      "============================================================\n",
      "WITH stop=['.'] ‚Äî stops at first period\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Albert Einstein is a famous scientist who made significant contributions to the field of physics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 0.20s | 96 chars\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Name a famous scientist and describe their contribution.\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"WITHOUT stop sequence\")\n",
    "print(\"=\" * 60)\n",
    "_ = generate(prompt)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"WITH stop=['.'] ‚Äî stops at first period\")\n",
    "print(\"=\" * 60)\n",
    "_ = generate(prompt, stop=[\".\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 7B: Stop Sequences for Structured Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "WITH stop=['\\n'] ‚Äî stops after extracting the name\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Sarah Chen"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 0.15s | 10 chars\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Extract the person's name from the text below.\n",
    "\n",
    "Text: \"Dr. Sarah Chen published her findings on climate change last Tuesday.\"\n",
    "\n",
    "Name:\"\"\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"WITH stop=['\\\\n'] ‚Äî stops after extracting the name\")\n",
    "print(\"=\" * 60)\n",
    "_ = generate(prompt, stop=[\"\\n\"], temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 7C: Stop Sequences to Prevent Role-Playing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "WITHOUT stop ‚Äî model might continue as 'User:' and 'Assistant:'\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Gravity is a fundamental force of nature that attracts two masses towards each other with an acceleration directly proportional to their masses and inversely proportional to the square of the distance between them."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 0.43s | 214 chars\n",
      "\n",
      "============================================================\n",
      "WITH stop=['User:', '\\n\\n'] ‚Äî halts after one response\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Gravity is a force that attracts two masses towards each other, with objects of greater mass having a stronger gravitational pull."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 0.28s | 130 chars\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Answer the user's question in one sentence.\n",
    "\n",
    "User: What is gravity?\n",
    "Assistant:\"\"\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"WITHOUT stop ‚Äî model might continue as 'User:' and 'Assistant:'\")\n",
    "print(\"=\" * 60)\n",
    "_ = generate(prompt, num_predict=200)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"WITH stop=['User:', '\\\\n\\\\n'] ‚Äî halts after one response\")\n",
    "print(\"=\" * 60)\n",
    "_ = generate(prompt, stop=[\"User:\", \"\\n\\n\"], num_predict=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Combining Parameters ‚Äî Real-World Recipes\n",
    "\n",
    "In practice, you'll combine multiple parameters together. Here are some common \"recipes\":\n",
    "\n",
    "| Use Case | Temperature | Top-P | Top-K | Repeat Penalty | Max Tokens |\n",
    "|----------|-------------|-------|-------|----------------|------------|\n",
    "| Factual Q&A | 0.0 | 1.0 | 1 | 1.0 | 100-200 |\n",
    "| Creative Writing | 0.9-1.2 | 0.9 | 50 | 1.2 | 500+ |\n",
    "| Code Generation | 0.0-0.2 | 0.95 | 40 | 1.1 | 500 |\n",
    "| Brainstorming | 1.0 | 0.95 | 100 | 1.3 | 300 |\n",
    "| Data Extraction | 0.0 | 1.0 | 1 | 1.0 | 100 |\n",
    "\n",
    "### Experiment 8A: Recipe Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  üìã Conservative (Factual style)\n",
      "  Parameters: temperature=0.1, top_p=1.0, top_k=1, repeat_penalty=1.0, num_predict=200\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "1. Personalized Health Assistant: This startup idea focuses on developing an AI-powered health assistant that can help individuals manage their health and wellness. The assistant can provide personalized health recommendations based on the user's medical history, lifestyle, and preferences. It can also monitor the user's health metrics such as heart rate, blood pressure, and sleep patterns, and provide alerts if any issues are detected.\n",
       "\n",
       "2. Smart Home Automation: This startup idea involves developing an AI-powered smart home automation system that can control various household appliances and devices using voice commands or smart home apps. The system can learn the user's preferences and habits, and automatically adjust the temperature, lighting, and security systems based on the user's schedule and preferences.\n",
       "\n",
       "3. AI-Powered Language Translation: This startup idea focuses on developing an AI-powered language translation system that can translate text and speech between different languages in real-time. The system can be used for international communication, remote work, and education. It can also be used for language learning and"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 1.84s | 1148 chars\n",
      "\n",
      "============================================================\n",
      "  ‚öñÔ∏è Balanced (General purpose)\n",
      "  Parameters: temperature=0.7, top_p=0.9, top_k=40, repeat_penalty=1.1, num_predict=200\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "1. AI-Powered Personalized Nutrition: Develop an app that uses machine learning algorithms to analyze your dietary habits and recommend personalized nutrition plans based on your health goals, preferences, and lifestyle.\n",
       "2. Virtual Reality Therapy for Anxiety Disorders: Create a platform using virtual reality technology to simulate anxiety-inducing situations and provide therapy sessions in a safe environment. This could help individuals with anxiety disorders learn coping mechanisms without the need for physical exposure to stressful situations.\n",
       "3. AI-Powered Language Translation Services: Develop an app that uses natural language processing techniques to translate between various languages in real-time, making it easy and convenient for people who communicate globally."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 1.20s | 781 chars\n",
      "\n",
      "============================================================\n",
      "  üöÄ Creative (Brainstorming)\n",
      "  Parameters: temperature=1.1, top_p=0.95, top_k=100, repeat_penalty=1.3, num_predict=200\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Here is the list of three different startups which can benefit from Artificial Intelligence technology:\n",
       "\n",
       "1) A start up that offers AI-powered chatbots for customer service: The goal here would be providing quick and efficient customer support via an intelligent agent, instead or calling a live human operator.\n",
       "\n",
       "2) An app to help remote workers with time management through the use of project management skills assisted by machine learning algorithms. 3\n",
       "\n",
       "3)a start up focused on creating personalized coaching plans that leverages AI-powered analysis - it offers insights based not only data collection but also cognitive ability and health factors, helping individual users achieve their training goals effectively while increasing productivity at work with no significant amount to pay for the service"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 1.32s | 803 chars\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Suggest 3 startup ideas related to artificial intelligence.\"\n",
    "\n",
    "configs = [\n",
    "    {\n",
    "        \"label\": \"üìã Conservative (Factual style)\",\n",
    "        \"temperature\": 0.1, \"top_p\": 1.0, \"top_k\": 1, \"repeat_penalty\": 1.0, \"num_predict\": 200\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"‚öñÔ∏è Balanced (General purpose)\",\n",
    "        \"temperature\": 0.7, \"top_p\": 0.9, \"top_k\": 40, \"repeat_penalty\": 1.1, \"num_predict\": 200\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"üöÄ Creative (Brainstorming)\",\n",
    "        \"temperature\": 1.1, \"top_p\": 0.95, \"top_k\": 100, \"repeat_penalty\": 1.3, \"num_predict\": 200\n",
    "    }\n",
    "]\n",
    "\n",
    "_ = compare(prompt, configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 8B: Code Generation Recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "  üéØ Precise Code (temp=0, top_k=1)\n",
      "  Parameters: temperature=0.0, top_k=1, num_predict=300\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "def is_palindrome(s):\n",
       "    \"\"\"\n",
       "    Check if the given string s is a palindrome.\n",
       "    \n",
       "    A palindrome is a word, phrase, number, or other sequence of characters which reads the same backward as forward.\n",
       "    \n",
       "    Parameters:\n",
       "    s (str): The string to check.\n",
       "    \n",
       "    Returns:\n",
       "    bool: True if s is a palindrome, False otherwise.\n",
       "    \"\"\"\n",
       "    # Normalize the string by removing spaces and converting to lowercase\n",
       "    normalized_str = ''.join(e for e in s.lower() if e.isalnum())\n",
       "    \n",
       "    # Check if the normalized string is equal to its reverse\n",
       "    return normalized_str == normalized_str[::-1]\n",
       "\n",
       "# Example usage:\n",
       "print(is_palindrome(\"A man, a plan, a canal: Panama\"))  # True\n",
       "print(is_palindrome(\"racecar\"))  # True\n",
       "print(is_palindrome(\"hello\"))  # False\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 1.77s | 766 chars\n",
      "\n",
      "============================================================\n",
      "  üé® Creative Code (temp=0.8, top_k=50)\n",
      "  Parameters: temperature=0.8, top_k=50, num_predict=300\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "def is_palindrome(s):\n",
       "    \"\"\"\n",
       "    Checks if a given string s is a palindrome.\n",
       "    \n",
       "    A palindrome reads the same backward as forward. This function will return True if the input string is a palindrome, and False otherwise.\n",
       "    \n",
       "    Parameters:\n",
       "    s (str): The string to check.\n",
       "\n",
       "    Returns:\n",
       "    bool: True if s is a palindrome, False otherwise.\n",
       "    \"\"\"\n",
       "    # Normalize the string by removing spaces and converting to lowercase\n",
       "    normalized = ''.join(e for e in s.lower() if e.isalnum())\n",
       "    \n",
       "    # Check if the string reads the same forwards as backwards\n",
       "    return normalized == normalized[::-1]\n",
       "\n",
       "# Example usage\n",
       "print(is_palindrome(\"A man, a plan, a canal: Panama\"))  # True\n",
       "print(is_palindrome(\"racecar\"))  # True\n",
       "print(is_palindrome(\"hello\"))  # False\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 1.72s | 774 chars\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Write a Python function that checks if a string is a palindrome.\"\n",
    "\n",
    "system = \"You are a Python developer. Write clean, well-commented code. Only output the code, nothing else.\"\n",
    "\n",
    "configs = [\n",
    "    {\n",
    "        \"label\": \"üéØ Precise Code (temp=0, top_k=1)\",\n",
    "        \"temperature\": 0.0, \"top_k\": 1, \"num_predict\": 300\n",
    "    },\n",
    "    {\n",
    "        \"label\": \"üé® Creative Code (temp=0.8, top_k=50)\",\n",
    "        \"temperature\": 0.8, \"top_k\": 50, \"num_predict\": 300\n",
    "    },\n",
    "]\n",
    "\n",
    "_ = compare(prompt, configs, system=system)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Sandbox ‚Äî Try It Yourself!\n",
    "\n",
    "Experiment with any combination of parameters below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOUR CUSTOM EXPERIMENT\n",
      "============================================================\n",
      "  temperature          = 0.7\n",
      "  top_p                = 0.9\n",
      "  top_k                = 40\n",
      "  num_predict          = 200\n",
      "  repeat_penalty       = 1.1\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The future of space travel will likely involve frequent, affordable trips to other planets with advanced propulsion technologies, sustainable habitats that minimize environmental impact, and increased accessibility for all, not just wealthy individuals or nations. As we explore further into deep space, we'll witness the evolution of space tourism becoming more inclusive and accessible, pushing boundaries in exploration and discovery beyond our current understanding of what is possible in interstellar travel."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è±Ô∏è 0.84s | 513 chars\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "#  SANDBOX - Tweak these values and re-run!\n",
    "# ============================================================\n",
    "\n",
    "my_prompt     = \"Describe the future of space travel in 3 sentences.\"\n",
    "my_system     = \"You are a futurist and science communicator.\"\n",
    "\n",
    "my_params = {\n",
    "    \"temperature\":    0.7,    # 0.0 to 2.0\n",
    "    \"top_p\":          0.9,    # 0.0 to 1.0\n",
    "    \"top_k\":          40,     # 1 to 100+\n",
    "    \"num_predict\":    200,    # max tokens to generate\n",
    "    \"repeat_penalty\": 1.1,    # 1.0 = off, higher = less repetition\n",
    "    # \"stop\":         [\".\"],  # uncomment to stop at first period\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "\n",
    "print(\"YOUR CUSTOM EXPERIMENT\")\n",
    "print(\"=\" * 60)\n",
    "params_str = '\\n'.join(f\"  {k:20s} = {v}\" for k, v in my_params.items())\n",
    "print(params_str)\n",
    "print(\"=\" * 60)\n",
    "_ = generate(my_prompt, system=my_system, **my_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "| Parameter | What It Does | Typical Range | When to Adjust |\n",
    "|-----------|-------------|---------------|----------------|\n",
    "| **Temperature** | Controls randomness | 0.0 ‚Äì 1.5 | Lower for facts, higher for creativity |\n",
    "| **Top-P** | Dynamic probability cutoff | 0.1 ‚Äì 1.0 | Use ~0.9 for general; lower for precision |\n",
    "| **Top-K** | Fixed candidate pool size | 1 ‚Äì 100 | 1 for greedy; 40-50 for balanced |\n",
    "| **Max Tokens** | Hard output length limit | 10 ‚Äì 4096 | Match to your expected output length |\n",
    "| **Frequency Penalty** | Penalizes repeated tokens proportionally | 1.0 ‚Äì 1.5 | Increase for less repetition |\n",
    "| **Presence Penalty** | Flat penalty on any used token | 1.0 ‚Äì 1.5 | Increase for broader vocabulary |\n",
    "| **Stop Sequences** | Halts generation at specific strings | N/A | Use for structured/single-line output |\n",
    "\n",
    "### Rules of Thumb\n",
    "\n",
    "1. **Start with defaults** ‚Äî temperature=0.7, top_p=0.9, top_k=40\n",
    "2. **Adjust one parameter at a time** ‚Äî so you can see what each one does\n",
    "3. **Temperature and Top-P overlap** ‚Äî usually tune one or the other, not both aggressively\n",
    "4. **Low temperature + Top-K=1** ‚Äî effectively deterministic (greedy decoding)\n",
    "5. **Stop sequences are underused** ‚Äî they're great for structured extraction tasks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
