{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 OpenAI API Deep Dive — Function Calling & Structured Outputs\n",
    "\n",
    "## Playground Notebook\n",
    "\n",
    "In this notebook, we'll explore two powerful features that make LLMs **actionable**:\n",
    "\n",
    "| Feature | What It Does |\n",
    "|---------|-------------|\n",
    "| **Function Calling** | Model decides *when* to call a function and *what arguments* to pass |\n",
    "| **Structured Outputs** | Guarantees the response matches an exact JSON schema |\n",
    "\n",
    "The model **never executes functions** — it tells your code what to run, then uses the result.\n",
    "\n",
    "> **Model:** `gpt-4o-mini` — supports both function calling and structured outputs.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Client ready | Model: gpt-4o-mini\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import display, Markdown, HTML\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "client = OpenAI()\n",
    "\n",
    "print(f\"\\u2705 Client ready | Model: {MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Helpers loaded\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "#  HELPER FUNCTIONS\n",
    "# ============================================================\n",
    "\n",
    "def chat(messages, max_tokens=150, **kwargs):\n",
    "    \"\"\"Send messages to OpenAI and display the response.\"\"\"\n",
    "    start = time.time()\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        max_tokens=max_tokens,\n",
    "        **kwargs\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    content = response.choices[0].message.content\n",
    "    if content:\n",
    "        display(Markdown(content))\n",
    "    print(f\"\\n\\u23f1\\ufe0f {elapsed:.2f}s | Tokens: {response.usage.prompt_tokens}+{response.usage.completion_tokens}={response.usage.total_tokens}\")\n",
    "    return response\n",
    "\n",
    "\n",
    "def show_messages(messages):\n",
    "    \"\"\"Pretty-print the message list being sent (handles both dicts and OpenAI objects).\"\"\"\n",
    "    colors = {\"system\": \"#e74c3c\", \"user\": \"#3498db\", \"assistant\": \"#2ecc71\", \"tool\": \"#f39c12\"}\n",
    "    html = \"\"\n",
    "    for msg in messages:\n",
    "        # Handle both dict and OpenAI message objects\n",
    "        if isinstance(msg, dict):\n",
    "            role = msg.get(\"role\", \"unknown\")\n",
    "            content = msg.get(\"content\", \"\")\n",
    "        else:\n",
    "            role = getattr(msg, \"role\", \"unknown\")\n",
    "            content = getattr(msg, \"content\", None)\n",
    "\n",
    "        # Handle tool_calls (assistant messages with no content)\n",
    "        if not content:\n",
    "            tool_calls = msg.get(\"tool_calls\", None) if isinstance(msg, dict) else getattr(msg, \"tool_calls\", None)\n",
    "            if tool_calls:\n",
    "                content = \", \".join(f\"{tc.function.name}({tc.function.arguments})\" for tc in tool_calls)\n",
    "                content = f\"[tool_calls] {content}\"\n",
    "            else:\n",
    "                content = \"(empty)\"\n",
    "\n",
    "        if len(str(content)) > 200:\n",
    "            content = str(content)[:200] + \"...\"\n",
    "\n",
    "        color = colors.get(role, \"#888\")\n",
    "        html += (\n",
    "            f'<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid {color};'\n",
    "            f'background:#1e1e1e;border-radius:4px;\">'\n",
    "            f'<strong style=\"color:{color};text-transform:uppercase;\">{role}</strong>'\n",
    "            f'<br><span style=\"color:#ccc;\">{content}</span></div>'\n",
    "        )\n",
    "    display(HTML(html))\n",
    "\n",
    "\n",
    "print(\"\\u2705 Helpers loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Function Calling — The Full Flow\n",
    "\n",
    "```\n",
    "1. You define functions and describe them to the model (tool schema)\n",
    "2. User sends a message\n",
    "3. Model responds with a tool_call (which function + what arguments)\n",
    "4. Your code executes the actual function\n",
    "5. You send the result back to the model\n",
    "6. Model uses the result to generate the final response\n",
    "```\n",
    "\n",
    "### Experiment 1A: Define a Function + Tool Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Function defined + tool schema ready\n",
      "\n",
      "Tool schema sent to the model:\n",
      "{\n",
      "  \"type\": \"function\",\n",
      "  \"function\": {\n",
      "    \"name\": \"get_weather\",\n",
      "    \"description\": \"Get the current weather for a given location.\",\n",
      "    \"parameters\": {\n",
      "      \"type\": \"object\",\n",
      "      \"properties\": {\n",
      "        \"location\": {\n",
      "          \"type\": \"string\",\n",
      "          \"description\": \"City name, e.g. 'New York'\"\n",
      "        },\n",
      "        \"unit\": {\n",
      "          \"type\": \"string\",\n",
      "          \"enum\": [\n",
      "            \"celsius\",\n",
      "            \"fahrenheit\"\n",
      "          ],\n",
      "          \"description\": \"Temperature unit\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"location\"\n",
      "      ]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Define the ACTUAL function your code will execute\n",
    "def get_weather(location: str, unit: str = \"celsius\") -> dict:\n",
    "    \"\"\"Simulate a weather API call.\"\"\"\n",
    "    # In production, this would call a real weather API\n",
    "    weather_data = {\n",
    "        \"new york\": {\"temp\": 22, \"condition\": \"Sunny\"},\n",
    "        \"london\":   {\"temp\": 15, \"condition\": \"Cloudy\"},\n",
    "        \"tokyo\":    {\"temp\": 28, \"condition\": \"Humid\"},\n",
    "    }\n",
    "    data = weather_data.get(location.lower(), {\"temp\": 20, \"condition\": \"Unknown\"})\n",
    "    if unit == \"fahrenheit\":\n",
    "        data[\"temp\"] = round(data[\"temp\"] * 9/5 + 32)\n",
    "    data[\"unit\"] = unit\n",
    "    data[\"location\"] = location\n",
    "    return data\n",
    "\n",
    "\n",
    "# Step 2: Describe it to the model (tool schema)\n",
    "weather_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_weather\",\n",
    "        \"description\": \"Get the current weather for a given location.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"City name, e.g. 'New York'\"\n",
    "                },\n",
    "                \"unit\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    \"description\": \"Temperature unit\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"location\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\u2705 Function defined + tool schema ready\")\n",
    "print(\"\\nTool schema sent to the model:\")\n",
    "print(json.dumps(weather_tool, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1B: Send Request — Model Decides to Call the Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">What's the weather in Tokyo?</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ 1.23s | Tokens: 77+14=91\n",
      "finish_reason: tool_calls\n",
      "\n",
      "✅ Model wants to call a function!\n",
      "   Function:  get_weather\n",
      "   Arguments: {\"location\":\"Tokyo\"}\n",
      "   Call ID:   call_pnoQkJqrRw0v7CbmcZ6zIVvp\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Send the request\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather in Tokyo?\"}\n",
    "]\n",
    "\n",
    "show_messages(messages)\n",
    "response = chat(messages, max_tokens=100, tools=[weather_tool])\n",
    "\n",
    "# Step 4: Check if the model wants to call a function\n",
    "choice = response.choices[0]\n",
    "print(f\"finish_reason: {choice.finish_reason}\")\n",
    "\n",
    "if choice.finish_reason == \"tool_calls\":\n",
    "    tool_call = choice.message.tool_calls[0]\n",
    "    print(f\"\\n\\u2705 Model wants to call a function!\")\n",
    "    print(f\"   Function:  {tool_call.function.name}\")\n",
    "    print(f\"   Arguments: {tool_call.function.arguments}\")\n",
    "    print(f\"   Call ID:   {tool_call.id}\")\n",
    "else:\n",
    "    print(f\"Model responded directly (no tool call needed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1C: Execute the Function & Send Result Back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function result: {'temp': 28, 'condition': 'Humid', 'unit': 'celsius', 'location': 'Tokyo'}\n",
      "\n",
      "============================================================\n",
      "Sending tool result back to model for final response:\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">What's the weather in Tokyo?</span></div><div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #2ecc71;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#2ecc71;text-transform:uppercase;\">assistant</strong><br><span style=\"color:#ccc;\">[tool_calls] get_weather({\"location\":\"Tokyo\"})</span></div><div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #f39c12;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#f39c12;text-transform:uppercase;\">tool</strong><br><span style=\"color:#ccc;\">{\"temp\": 28, \"condition\": \"Humid\", \"unit\": \"celsius\", \"location\": \"Tokyo\"}</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The current weather in Tokyo is 28°C and humid."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ 0.72s | Tokens: 61+12=73\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Execute the function with the model's arguments\n",
    "args = json.loads(tool_call.function.arguments)\n",
    "result = get_weather(**args)\n",
    "print(f\"Function result: {result}\")\n",
    "\n",
    "# Step 6: Send the result back to the model\n",
    "messages.append(choice.message)  # include the assistant's tool_call message\n",
    "messages.append({\n",
    "    \"role\": \"tool\",\n",
    "    \"tool_call_id\": tool_call.id,\n",
    "    \"content\": json.dumps(result)\n",
    "})\n",
    "\n",
    "# Model generates final response using the function result\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"Sending tool result back to model for final response:\")\n",
    "print(f\"{'=' * 60}\")\n",
    "show_messages(messages)\n",
    "final_response = chat(messages, max_tokens=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1D: `tool_choice` — Controlling When Functions Are Called\n",
    "\n",
    "| Value | Behavior |\n",
    "|-------|----------|\n",
    "| `\"auto\"` | Model decides (default) |\n",
    "| `\"none\"` | Model will NOT call any function |\n",
    "| `\"required\"` | Model MUST call a function |\n",
    "| `{\"type\": \"function\", \"function\": {\"name\": \"...\"}}` | Force a specific function |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "tool_choice='none' — Model answers directly, ignores tools\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">What's the weather in London?</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "What temperature unit would you like for the weather in London: Celsius or Fahrenheit?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ 0.87s | Tokens: 78+16=94\n",
      "finish_reason: stop\n",
      "\n",
      "============================================================\n",
      "tool_choice='required' — Model forced to call function even for a joke\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">Tell me a joke.</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ 0.90s | Tokens: 76+15=91\n",
      "  Function: get_weather\n",
      "  Args: {\"location\":\"New York\"}\n"
     ]
    }
   ],
   "source": [
    "# tool_choice=\"none\" — model answers directly, ignores tools\n",
    "print(\"=\" * 60)\n",
    "print(\"tool_choice='none' — Model answers directly, ignores tools\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What's the weather in London?\"}]\n",
    "show_messages(messages)\n",
    "response = chat(messages, max_tokens=60, tools=[weather_tool], tool_choice=\"none\")\n",
    "print(f\"finish_reason: {response.choices[0].finish_reason}\")\n",
    "\n",
    "# tool_choice=\"required\" — model MUST call a function\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"tool_choice='required' — Model forced to call function even for a joke\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "messages2 = [{\"role\": \"user\", \"content\": \"Tell me a joke.\"}]\n",
    "show_messages(messages2)\n",
    "response2 = chat(messages2, max_tokens=60, tools=[weather_tool], tool_choice=\"required\")\n",
    "\n",
    "tc = response2.choices[0].message.tool_calls[0]\n",
    "print(f\"  Function: {tc.function.name}\")\n",
    "print(f\"  Args: {tc.function.arguments}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1E: Multiple Tools — Model Picks the Right One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">What's the weather in New York?</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ 0.99s | Tokens: 116+15=131\n",
      "  → Calls: get_weather({\"location\":\"New York\"})\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">What is 15 * 23 + 7?</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ 1.00s | Tokens: 120+19=139\n",
      "  → Calls: calculate({\"expression\":\"15 * 23 + 7\"})\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">Hello, how are you?</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to assist you. How can I help you today?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ 1.47s | Tokens: 115+31=146\n",
      "  → Direct response (no tool needed)\n"
     ]
    }
   ],
   "source": [
    "# Define a second function\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Evaluate a math expression safely.\"\"\"\n",
    "    try:\n",
    "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "\n",
    "calc_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"calculate\",\n",
    "        \"description\": \"Evaluate a mathematical expression and return the result.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"expression\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Math expression, e.g. '2 * 3 + 4'\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"expression\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "tools = [weather_tool, calc_tool]\n",
    "\n",
    "# Test with different queries — model picks the right tool\n",
    "queries = [\n",
    "    \"What's the weather in New York?\",\n",
    "    \"What is 15 * 23 + 7?\",\n",
    "    \"Hello, how are you?\"  # no tool needed\n",
    "]\n",
    "\n",
    "for q in queries:\n",
    "    print(f\"\\n{'=' * 50}\")\n",
    "    messages = [{\"role\": \"user\", \"content\": q}]\n",
    "    show_messages(messages)\n",
    "    resp = chat(messages, max_tokens=60, tools=tools)\n",
    "\n",
    "    choice = resp.choices[0]\n",
    "    if choice.finish_reason == \"tool_calls\":\n",
    "        for tc in choice.message.tool_calls:\n",
    "            print(f\"  \\u2192 Calls: {tc.function.name}({tc.function.arguments})\")\n",
    "    else:\n",
    "        print(f\"  \\u2192 Direct response (no tool needed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1F: Parallel Tool Calls\n",
    "\n",
    "When a user asks something that requires **multiple functions**, the model can call them all at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">Compare weather in Tokyo and London.</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ 2.11s | Tokens: 78+54=132\n",
      "✅ Model made 2 parallel tool calls!\n",
      "\n",
      "  get_weather({'location': 'Tokyo', 'unit': 'celsius'}) → {'temp': 28, 'condition': 'Humid', 'unit': 'celsius', 'location': 'Tokyo'}\n",
      "  get_weather({'location': 'London', 'unit': 'celsius'}) → {'temp': 15, 'condition': 'Cloudy', 'unit': 'celsius', 'location': 'London'}\n",
      "\n",
      "============================================================\n",
      "Final response with both results:\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">Compare weather in Tokyo and London.</span></div><div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #2ecc71;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#2ecc71;text-transform:uppercase;\">assistant</strong><br><span style=\"color:#ccc;\">[tool_calls] get_weather({\"location\": \"Tokyo\", \"unit\": \"celsius\"}), get_weather({\"location\": \"London\", \"unit\": \"celsius\"})</span></div><div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #f39c12;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#f39c12;text-transform:uppercase;\">tool</strong><br><span style=\"color:#ccc;\">{\"temp\": 28, \"condition\": \"Humid\", \"unit\": \"celsius\", \"location\": \"Tokyo\"}</span></div><div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #f39c12;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#f39c12;text-transform:uppercase;\">tool</strong><br><span style=\"color:#ccc;\">{\"temp\": 15, \"condition\": \"Cloudy\", \"unit\": \"celsius\", \"location\": \"London\"}</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "As of the latest weather updates:\n",
       "\n",
       "- **Tokyo**: The temperature is 28°C with humid conditions.\n",
       "- **London**: The temperature is 15°C and it is cloudy.\n",
       "\n",
       "In summary, Tokyo is currently much warmer and more humid compared to the cooler and cloudier weather in London."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ 1.32s | Tokens: 132+60=192\n"
     ]
    }
   ],
   "source": [
    "# Ask about weather in two cities — model may call get_weather twice in parallel\n",
    "messages = [{\"role\": \"user\", \"content\": \"Compare weather in Tokyo and London.\"}]\n",
    "show_messages(messages)\n",
    "response = chat(messages, max_tokens=100, tools=[weather_tool])\n",
    "\n",
    "choice = response.choices[0]\n",
    "if choice.finish_reason == \"tool_calls\":\n",
    "    print(f\"\\u2705 Model made {len(choice.message.tool_calls)} parallel tool calls!\\n\")\n",
    "\n",
    "    # Execute all functions\n",
    "    messages.append(choice.message)\n",
    "\n",
    "    available_functions = {\"get_weather\": get_weather, \"calculate\": calculate}\n",
    "\n",
    "    for tc in choice.message.tool_calls:\n",
    "        fn = available_functions[tc.function.name]\n",
    "        args = json.loads(tc.function.arguments)\n",
    "        result = fn(**args)\n",
    "        print(f\"  {tc.function.name}({args}) \\u2192 {result}\")\n",
    "        messages.append({\n",
    "            \"role\": \"tool\",\n",
    "            \"tool_call_id\": tc.id,\n",
    "            \"content\": json.dumps(result)\n",
    "        })\n",
    "\n",
    "    # Get final response\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(\"Final response with both results:\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "    show_messages(messages)\n",
    "    final = chat(messages, max_tokens=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Structured Outputs — Guaranteed JSON Schema\n",
    "\n",
    "Structured Outputs guarantee the model's response always matches a schema you define — valid JSON, every field present, correct data types.\n",
    "\n",
    "### Method 1: JSON Mode (Simple, Less Strict)\n",
    "\n",
    "Guarantees valid JSON but does **not** enforce a specific schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #e74c3c;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#e74c3c;text-transform:uppercase;\">system</strong><br><span style=\"color:#ccc;\">Extract info as JSON with keys: name, topic, key_points (list).</span></div><div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">Marie Curie discovered radioactivity, won two Nobel Prizes, and pioneered radiation therapy.</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "{\n",
       "  \"name\": \"Marie Curie\",\n",
       "  \"topic\": \"Achievements in Science\",\n",
       "  \"key_points\": [\n",
       "    \"Discovered radioactivity\",\n",
       "    \"Won two Nobel Prizes\",\n",
       "    \"Pioneered radiation therapy\"\n",
       "  ]\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ 2.02s | Tokens: 45+51=96\n",
      "✅ Valid JSON! Keys: ['name', 'topic', 'key_points']\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Extract info as JSON with keys: name, topic, key_points (list).\"},\n",
    "    {\"role\": \"user\", \"content\": \"Marie Curie discovered radioactivity, won two Nobel Prizes, and pioneered radiation therapy.\"}\n",
    "]\n",
    "\n",
    "show_messages(messages)\n",
    "response = chat(messages, max_tokens=120, response_format={\"type\": \"json_object\"})\n",
    "\n",
    "text = response.choices[0].message.content\n",
    "try:\n",
    "    parsed = json.loads(text)\n",
    "    print(f\"\\u2705 Valid JSON! Keys: {list(parsed.keys())}\")\n",
    "except json.JSONDecodeError:\n",
    "    print(\"\\u274c Not valid JSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Structured Outputs with Pydantic (Strict, Recommended)\n",
    "\n",
    "Define your exact schema using **Pydantic** — OpenAI guarantees the response matches it every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #e74c3c;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#e74c3c;text-transform:uppercase;\">system</strong><br><span style=\"color:#ccc;\">Extract structured information from the text.</span></div><div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">Alan Turing invented the concept of the Turing machine, broke the Enigma code, and laid the foundations of computer science.</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Parsed into Pydantic object:\n",
      "   Name:       Alan Turing\n",
      "   Topic:      Contributions to Computer Science\n",
      "   Key Points: ['Invented the concept of the Turing machine', 'Broke the Enigma code', 'Laid the foundations of computer science']\n",
      "   Type:       PersonInfo\n",
      "\n",
      "⏱️ Tokens: 110+44=154\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class PersonInfo(BaseModel):\n",
    "    name: str\n",
    "    topic: str\n",
    "    key_points: list[str]\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Extract structured information from the text.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Alan Turing invented the concept of the Turing machine, broke the Enigma code, and laid the foundations of computer science.\"}\n",
    "]\n",
    "\n",
    "show_messages(messages)\n",
    "\n",
    "response = client.beta.chat.completions.parse(\n",
    "    model=MODEL,\n",
    "    messages=messages,\n",
    "    response_format=PersonInfo,\n",
    "    max_tokens=120\n",
    ")\n",
    "\n",
    "result = response.choices[0].message.parsed\n",
    "print(f\"\\u2705 Parsed into Pydantic object:\")\n",
    "print(f\"   Name:       {result.name}\")\n",
    "print(f\"   Topic:      {result.topic}\")\n",
    "print(f\"   Key Points: {result.key_points}\")\n",
    "print(f\"   Type:       {type(result).__name__}\")\n",
    "print(f\"\\n\\u23f1\\ufe0f Tokens: {response.usage.prompt_tokens}+{response.usage.completion_tokens}={response.usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2C: Nested Schemas — Complex Structured Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #e74c3c;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#e74c3c;text-transform:uppercase;\">system</strong><br><span style=\"color:#ccc;\">Extract company information.</span></div><div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">Tesla, founded in 2003, is an electric vehicle company headquartered in Austin, USA. They make the Model 3, Model Y, and Cybertruck.</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Parsed nested Pydantic object:\n",
      "   Company:   Tesla\n",
      "   Industry:  Electric Vehicles\n",
      "   Founded:   2003\n",
      "   HQ:        Austin, USA\n",
      "   Products:  ['Model 3', 'Model Y', 'Cybertruck']\n",
      "\n",
      "⏱️ Tokens: 183+42=225\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "\n",
    "class Address(BaseModel):\n",
    "    city: str\n",
    "    country: str\n",
    "\n",
    "\n",
    "class Company(BaseModel):\n",
    "    name: str\n",
    "    industry: str\n",
    "    founded_year: Optional[int]\n",
    "    headquarters: Address\n",
    "    products: list[str]\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Extract company information.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tesla, founded in 2003, is an electric vehicle company headquartered in Austin, USA. They make the Model 3, Model Y, and Cybertruck.\"}\n",
    "]\n",
    "\n",
    "show_messages(messages)\n",
    "\n",
    "response = client.beta.chat.completions.parse(\n",
    "    model=MODEL,\n",
    "    messages=messages,\n",
    "    response_format=Company,\n",
    "    max_tokens=120\n",
    ")\n",
    "\n",
    "company = response.choices[0].message.parsed\n",
    "print(f\"\\u2705 Parsed nested Pydantic object:\")\n",
    "print(f\"   Company:   {company.name}\")\n",
    "print(f\"   Industry:  {company.industry}\")\n",
    "print(f\"   Founded:   {company.founded_year}\")\n",
    "print(f\"   HQ:        {company.headquarters.city}, {company.headquarters.country}\")\n",
    "print(f\"   Products:  {company.products}\")\n",
    "print(f\"\\n\\u23f1\\ufe0f Tokens: {response.usage.prompt_tokens}+{response.usage.completion_tokens}={response.usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON Mode vs Structured Outputs — When to Use Which\n",
    "\n",
    "| Feature | JSON Mode | Structured Outputs (Pydantic) |\n",
    "|---------|-----------|-------------------------------|\n",
    "| Valid JSON? | \\u2705 Yes | \\u2705 Yes |\n",
    "| Schema enforced? | \\u274c No | \\u2705 Yes — every field, every type |\n",
    "| Setup effort | Minimal | Define Pydantic models |\n",
    "| Parsing needed? | Yes (json.loads) | No — direct `.parsed` access |\n",
    "| Best for | Quick extraction | Production data pipelines |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Combining Function Calling + Structured Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Step 1: Send request with tools\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #e74c3c;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#e74c3c;text-transform:uppercase;\">system</strong><br><span style=\"color:#ccc;\">You are a weather assistant. Use the weather tool, then summarize.</span></div><div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">What's the weather in New York?</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ 0.73s | Tokens: 92+15=107\n",
      "\n",
      "============================================================\n",
      "Step 2: Execute function → {'temp': 22, 'condition': 'Sunny', 'unit': 'celsius', 'location': 'New York'}\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Step 3: Get structured final response\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #e74c3c;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#e74c3c;text-transform:uppercase;\">system</strong><br><span style=\"color:#ccc;\">You are a weather assistant. Use the weather tool, then summarize.</span></div><div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">What's the weather in New York?</span></div><div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #2ecc71;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#2ecc71;text-transform:uppercase;\">assistant</strong><br><span style=\"color:#ccc;\">[tool_calls] get_weather({\"location\":\"New York\"})</span></div><div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #f39c12;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#f39c12;text-transform:uppercase;\">tool</strong><br><span style=\"color:#ccc;\">{\"temp\": 22, \"condition\": \"Sunny\", \"unit\": \"celsius\", \"location\": \"New York\"}</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Structured Report:\n",
      "   Location:       New York\n",
      "   Temperature:    22\n",
      "   Condition:      Sunny\n",
      "   Recommendation: A great day for outdoor activities!\n",
      "\n",
      "⏱️ Tokens: 150+25=175\n"
     ]
    }
   ],
   "source": [
    "# A complete tool-calling loop with structured final output\n",
    "\n",
    "class WeatherReport(BaseModel):\n",
    "    location: str\n",
    "    temperature: int\n",
    "    condition: str\n",
    "    recommendation: str\n",
    "\n",
    "\n",
    "# Step 1: Ask with tools\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a weather assistant. Use the weather tool, then summarize.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's the weather in New York?\"}\n",
    "]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Step 1: Send request with tools\")\n",
    "print(\"=\" * 60)\n",
    "show_messages(messages)\n",
    "resp = chat(messages, max_tokens=100, tools=[weather_tool])\n",
    "\n",
    "# Step 2: Execute tool call\n",
    "if resp.choices[0].finish_reason == \"tool_calls\":\n",
    "    tc = resp.choices[0].message.tool_calls[0]\n",
    "    args = json.loads(tc.function.arguments)\n",
    "    result = get_weather(**args)\n",
    "\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"Step 2: Execute function \\u2192 {result}\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "\n",
    "    messages.append(resp.choices[0].message)\n",
    "    messages.append({\"role\": \"tool\", \"tool_call_id\": tc.id, \"content\": json.dumps(result)})\n",
    "\n",
    "    # Step 3: Get structured final response\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(\"Step 3: Get structured final response\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "    show_messages(messages)\n",
    "\n",
    "    final = client.beta.chat.completions.parse(\n",
    "        model=MODEL, messages=messages,\n",
    "        response_format=WeatherReport, max_tokens=100\n",
    "    )\n",
    "\n",
    "    report = final.choices[0].message.parsed\n",
    "    print(f\"\\u2705 Structured Report:\")\n",
    "    print(f\"   Location:       {report.location}\")\n",
    "    print(f\"   Temperature:    {report.temperature}\")\n",
    "    print(f\"   Condition:      {report.condition}\")\n",
    "    print(f\"   Recommendation: {report.recommendation}\")\n",
    "    print(f\"\\n\\u23f1\\ufe0f Tokens: {final.usage.prompt_tokens}+{final.usage.completion_tokens}={final.usage.total_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Sandbox — Try It Yourself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">What is the capital of India?</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ 0.81s | Tokens: 58+15=73\n",
      "Tool called: lookup_capital({'country': 'India'}) → New Delhi\n",
      "\n",
      "============================================================\n",
      "Final response:\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #3498db;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#3498db;text-transform:uppercase;\">user</strong><br><span style=\"color:#ccc;\">What is the capital of India?</span></div><div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #2ecc71;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#2ecc71;text-transform:uppercase;\">assistant</strong><br><span style=\"color:#ccc;\">[tool_calls] lookup_capital({\"country\":\"India\"})</span></div><div style=\"margin:6px 0;padding:8px 12px;border-left:4px solid #f39c12;background:#1e1e1e;border-radius:4px;\"><strong style=\"color:#f39c12;text-transform:uppercase;\">tool</strong><br><span style=\"color:#ccc;\">New Delhi</span></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The capital of India is New Delhi."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⏱️ 0.74s | Tokens: 40+8=48\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "#  SANDBOX — Define your own function + tool schema\n",
    "# ============================================================\n",
    "\n",
    "# Example: A simple lookup tool\n",
    "def lookup_capital(country: str) -> str:\n",
    "    capitals = {\"france\": \"Paris\", \"japan\": \"Tokyo\", \"brazil\": \"Brasilia\", \"india\": \"New Delhi\"}\n",
    "    return capitals.get(country.lower(), \"Unknown\")\n",
    "\n",
    "\n",
    "capital_tool = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"lookup_capital\",\n",
    "        \"description\": \"Look up the capital city of a country.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"country\": {\"type\": \"string\", \"description\": \"Country name\"}\n",
    "            },\n",
    "            \"required\": [\"country\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Try it!\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is the capital of India?\"}]\n",
    "show_messages(messages)\n",
    "resp = chat(messages, max_tokens=60, tools=[capital_tool])\n",
    "\n",
    "choice = resp.choices[0]\n",
    "if choice.finish_reason == \"tool_calls\":\n",
    "    tc = choice.message.tool_calls[0]\n",
    "    args = json.loads(tc.function.arguments)\n",
    "    result = lookup_capital(**args)\n",
    "    print(f\"Tool called: {tc.function.name}({args}) \\u2192 {result}\")\n",
    "\n",
    "    messages.append(choice.message)\n",
    "    messages.append({\"role\": \"tool\", \"tool_call_id\": tc.id, \"content\": result})\n",
    "\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(\"Final response:\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "    show_messages(messages)\n",
    "    final = chat(messages, max_tokens=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "| Concept | What to Remember |\n",
    "|---------|------------------|\n",
    "| **Function Calling** | Model decides *when* and *what* to call — your code executes it |\n",
    "| **Tool Schema** | JSON description of your function — name, description, parameters |\n",
    "| **tool_calls** | The model's response when it wants to call a function |\n",
    "| **tool_choice** | `auto` (default), `none`, `required`, or force a specific function |\n",
    "| **Parallel Calls** | Model can call multiple functions in one response |\n",
    "| **JSON Mode** | `response_format={\"type\": \"json_object\"}` — valid JSON, no schema |\n",
    "| **Structured Outputs** | `response_format=PydanticModel` — exact schema, typed, guaranteed |\n",
    "| **`.parsed`** | Direct access to Pydantic object — no manual JSON parsing |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
